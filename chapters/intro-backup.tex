\FloatBarrier
\section{Motivation and Project Aims}\label{sec:motivation}
The human eye is capable of forming images over large depths of field with single photon sensitivity. The eye is also susceptible to disease often resulting permanent loss of vision if left undiagnosed and untreated. One of the most common retinal diseases, affecting the elderly, Age-Related Macular Degeneration (AMD), affects \qty{20}{\percent} of the population and in a \num{12} month period this disease can progress the initial symptoms to permanent loss of some central vision~\cite{lim2012age}. Routine and regular retinal imaging is a key tool in the early detection of retinal disease, and for developing understanding of disease pathophysiology and effective treatment. Current retinal imaging techniques, such as Scanning Laser Ophthalmoscopy (SLO), aim to detect structure abnormalities in images of the retina surface covering \qty{82}{\percent} of the retinal surface (OPTOS Monaco, Silverstone SLO) and resolution of \qty{15}{\um}~\cite{ashraf2022comparison} to diagnose and track progression of common retinal disease such as AMD, Glaucoma, Diabetic Retinopathy, and retinal detachments.
\\
Here lies a fundamental issue with current interventions in retinal disease - they occur after physical damage to the retina is detected or changes in vision are reported by the patient. At this stage, treatment options degrade into maintaining and abating permanent loss of vision. If instead, the progression of disease can be tracked at the level of local biochemical imbalances or metabolic dysfunction - before the occurrence of physical damage to vision - disease can be more effectively detected, studied, and treated.
Naturally fluorescent biomarkers, can be quantitatively imaged to all metabolic function in the retina to be measured. For example: a biomarker found in the retina, Flavin Adenine Dinucleotide (FAD), is a by-product of the consumption of oxygen and could indicate local metabolic health in the retina; and Advanced Glycation End-products (AGEs) are linked with the progression of diabetic retinopathy~\cite{yamagishi2011advanced,milne2013advanced}. Fluorescence imaging in the retina - termed fundus autofluorescence imaging in the literature - is widely used, qualitatively, in clinical ophthalmology for resolving markers of AMD progression, drusen, and damage to other retinal structures~\cite{yung2016clinical}. Fluorescence imaging of the retina is hindered by several fundamental limitations. Namely, the low intensity threshold for safe exposure coupled with the feint signal produced from excited fluorophores of interest being polluted by fluorescent clutter results in high noise images with poor contrast and resolution (when compared to wide-field reflectance images). This dominant fluorescent clutter also degrades the ability to quantify the concentration of individual fluorophores and map their distribution across the retina even with advanced spectral imaging techniques.
\\
Fluorescence Lifetime Imaging Microscopy (FLIM) is an emergent field of microscopy where the differences in nanosecond-scale time that a fluorophore remains excited for is used a contrast mediums to form images. FLIM brings unique advantages in that the fluorescence lifetime is intrinsic to each fluorophore but is also invariant to the local concentration or quantum efficiency of the fluorophore. This means that weakly emitting fluorophores of interest can be isolated from complex mixtures if the limitations of low-photon counts or high shot-noise can be overcome. Commonly, biological structures, or proteins of interest, are labelled with dyes to fluoresce more intensely than the autofluorescence of endogenous fluorophores allowing more complex mechanisms to be exploited: viscosity and tension within tissue can be probed~\cite{ringer2017multiplexing,kashirina2020monitoring}; intramolecular distances can be measured through F\"orster Resonance Energy Transfer (FRET)~\cite{haenni2013intramolecular}; and even sub-diffraction limit volumetric imaging can be achieved~\cite{shtengel2009interferometric}. In the retina, endogenous fluorophores of interest exhibit high-overlap of their fluorescence emission spectra and fluorescence decay properties introducing additional challenges.
\\
The techniques of FLIM have recently been adapted for clinical ophthalmology in the field of Fluorescence lifetime Imaging Ophthalmoscopy (FLIO) to explore the diagnostic use that fluorescence lifetimes may offer~\cite{dysli2017fluorescence}. Fluorescence lifetimes are extracted from histograms of arrival times of fluorescence photons to construct a map of fluorescence lifetimes across the retina. With this device the connection between measured fluorescence lifetimes and retinal disease progression was explored by qualitatively comparing lifetime maps of age and gender matched healthy patients with patients exhibiting a retinal disease such as AMD, Diabetic Retinopathy, and Stargardts disease~\cite{zinkernagel2019fluorescence}. These \textit{in-vivo} studies focus on qualitative comparisons in part due to the relative youth of the field as well as the poor understanding of the specific biochemical imbalances that occur in the retina, and the body, at the onset of retinal disease.
\\
A key deficiency in current retinal imaging techniques is the ability to quantitatively assess retinal health. Previously, measurements of vascular oxygen concentrations in retinal vasculature have been reported using the spectral properties of oxygenated and deoxygenated haemoglobin~\cite{stefansson2019retinal,mordant2011spectral}. Although, the uncertainties in the measurements of $O_{2}$ concentrations are larger than the variability that would typically be experienced throughout the progression of a retinal disease. Fluorescence lifetime imaging could facilitate a similar quantitative approach to monitoring retinal metabolic health but the efficient use of the available signal will be paramount for ensuring this technology can be feasibly implemented into diagnostic practise.
\\
In this thesis, a Commercial-Of-The-Shelf (COTS) fundus camera is modified to enable spectrally resolved FLIM measurements of the retina,  and a new method of recovering fluorophore concentrations from SFLIM measurements is developed. Using this new instrument and algorithm, the feasibility of measuring retinal FAD concentrations in the retina is assessed by inducing changes in oxygen consumption anathematised rat and measuring commensurate changes in retinal FAD concentrations.
\FloatBarrier
\section{Morphology The Eye and \\Common Retinal Diseases}
In this section, the structures of the eye and their functions will be described before common retinal diseases and their symptoms are discussed. In the final parts of this section the devices used in the routine detection of retinal disease will be described.
\FloatBarrier
\subsection{Morphology of the Eye}
The human eye is a complex organ, capable of forming images with an angular resolving power of around 1 arc-minute with single photon sensitivity~\cite{tinsley2016direct}. Optically, the eye can be thought of as an infinite-conjugate imaging system with a
front illuminated sensor where the cornea and the eyes lens form images -through the retinal vasculature - onto the retina.
\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.55\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/introduction/AnatomyofEye.png}
        \caption{}
        \label{figintro:eyeball}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/introduction/fasebj2017retinalayer2.pdf}
        \caption{}
        \label{figintro:retinalayer}
    \end{subfigure}
    \caption{Diagram of the key parts that comprise the human eye.~\subref{figintro:eyeball}) breaks down the main structures.~\subref{figintro:retinalayer}) the different layers of the retina. The superficial intermediate, and deep vasculature reside between the Nerve Fibre Layer (NFL), Inner Nuclear Layer (INL), and Outer Nuclear Layer (ONL), respectively. The layers responsible for the conversion of light into neuronal activity are the Inner, and Outer Segments (IS,OS) of the photoreceptors and the Ganglion Cell Layer (GCL) and are supported by the Retinal Pigment Epithelium (RPE).Figure (\subref{figintro:eyeball}) from Fig. 2 of~\citeauthor{kolb2007EyeAnatomy} and (\subref{figintro:retinalayer}) from Fig. 1b of~\citeauthor{liu2017animal}~\cite{kolb2007EyeAnatomy,liu2017animal}.}
    \label{figintro:eyeanatomy}
\end{figure}
The structures within the eye can be described as the anterior and posterior segment.
\FloatBarrier
\subsubsection{Anterior Segment}
The cornea protrudes at the front of the eye - making it non-spherical - and is responsible for providing protection for the lens, as well as contributing more than half of the refractive power of the eye. The pigmented iris and pupil form the aperture of the eye and is continuously is adjustable from \qtyrange{2}{8}{\mm} in diameter as a response to the intensity of ambient light. The eyes crystalline lens has a diameter of \qtyrange{8}{10}{\mm} and is responsible for fine focusing, and forming - what is perceived by brain as aberration-free - images onto the retina. With both eyes working as a pair a \qty{200}{\degree} Field-Of-View (FOV) can be perceived by the brain.
The eye also contains two humours: the aqueous humour that occupies the volume between the cornea and the lens, and the vitreuos humour which fills the volume behind the lens up to the retina. These humours continuously flow through the eye and ensure tissues in the eye are fed with nutrients and maintain the eyes shape.
\FloatBarrier
\subsubsection{Posterior Segment}
The retina is a \qty{250}{\micro\metre} thick, photo-sensitive multi-layer slice of tissue located at the rear of the eyeball with blood vessels on the surface supplying it with oxygenated blood. The top layers of the retina contain the arteries and veins that supply oxygenated blood to the tissue, fed by the ophthalmic artery, and the photoreceptors as well as the inner, and outer, nuclear layers which are responsible for detecting incident photons and and converting them into neuronal activity which is transmitted down the optic nerve through a small gap, devoid of photoreceptors, called the optic disk. Around the optic disk the density of photoreceptors varies to make up the different types of vision. The macula and fovea contain the highest concentrations of photoreceptors to make up the central vision - $\approx \SI{60}{\degree}$ FOV - with the rest of the retinal surface making up peripheral vision~\cite{bringmann2021fovea}. 
Behind the photoreceptors exists the Retinal Pigment Epithelium (RPE) - referred to as the pigment epithelium in~\cref{figintro:eyeanatomy} - which serves as a support structure for the front most layers of the retina as well as choroid and Bruch's membrane which provide blood and nutrients to the RPE and photoreceptors.
\FloatBarrier
\subsection{Common Retinal diseases - \\ Their Indicators and Progression}
\FloatBarrier
\subsubsection{Age-Related Macular Degeneration}\label{subsubsec:intro-amd}
AMD is progressive disease which results in permanent loss of central vision. Initially, patients present as asymptomatic but in retinal images show the formation of small yellowish deposits in the RPE referred to as ``drusen’’ and progresses as one of two types - ``wet’’ and ``dry’’ AMD. Wet AMD causes abnormal blood vessels to form in the choroid which rupture the RPE and leak blood into the retina, culminating in retinal scarring and permanent vision loss~\cite{abdelsalam1999drusen,bressler2002early}. Dry AMD also progresses towards permanent vision loss where the photoreceptors atrophy –Geographic Atrophy - but with regular screening this type can be treated with intra-retinal injections~\cite{lim2012age,bressler2002early}. Progression of AMD is usually monitored by tracking the change in drusen and any areas of Geographic Atrophy, as shown in~\cref{fig:introAMD}.
\begin{figure}
    \centering
    \begin{annotatedFigure}{\includegraphics[width = 0.95\textwidth]{figures/introduction/AMD-progressionFigure.pdf}}
        \annotatedFigureText{0.02,0.84}{white}{0.3}{a)}
        \annotatedFigureText{0.35,0.84}{white}{0.3}{b)}
        \annotatedFigureBox{0.5,0.65}{0.54,0.5}{1}{0.547,0.47}
        \annotatedFigureBox{0.7,0.7}{0.85,0.1}{2}{0.69,0.72}
        \annotatedFigureText{0.67,0.84}{white}{0.3}{c)}
    \end{annotatedFigure}
    \caption{Progression of AMD. In a) a healthy retina of an elderly patient, with no signs of AMD, is shown. b) Retina showing signs of AMD with intermediate sized drusen (\cref{tab:drusen}) denoted as (1). c) shows a retina in the advanced stages of AMD displaying an large area of Geographic Atrophy (2). Adapted from Fig.~1 of~\citeauthor{guymer2023age}~\cite{guymer2023age}.}
    \label{fig:introAMD}
\end{figure}

Drusen deposits are classified into ``soft’’ and ``hard’’ densities where hard drusen tend to be smaller in size and present a lower risk of vision loss than soft drusen. Soft drusen has been hypothesised to be the result of hard drusen breaking down~\cite{sarks1994evolution} and are detected in fluorescence images of the retina~\cite{yung2016clinical}. In~\cref{tab:drusen}, the criteria for characterising the size of drusen are described where small drusen tend to grow into larger drusen.
\begin{table}[htp]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        Category & Diameter (\unit{\um})\\
        \hline
        Small & $<63$\\
        Intermediate &\numrange{63}{124}\\
        Large & $\geq\num{125}$\\
        \hline
    \end{tabular}
    \caption{Criteria for categorising retinal drusen based on average diameter. Transcribed from~\citeauthor{guymer2023age}~\cite{guymer2023age}.}
    \label{tab:drusen}
\end{table}
\FloatBarrier
\subsubsection{Diabetic Retinopathy}\label{subsubsec:intro-dr}
Diabetic retinopathy is a complication of diabetes affecting nearly all Type 1 diabetic and over \qty{60}{\percent} of Type 2 diabetics within two decades of receiving a diagnosis of diabetes~\cite{fong2004retinopathy}. Chronic high concentrations glucose in the blood – hyperglycaemia and large fluctuations in this blood-glucose concentration result in dysfunction in the retinal vasculature. As shown in~\cref{fig:introNPDR}, Blood vessels can swell and cause macular oedemas and micro-aneurysms into the vitreous humour around the macula~\cite{kowluru2007oxidative,mohamed2007management}.
\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.65\textwidth}
        \centering
        \includegraphics[width = \textwidth]{figures/introduction/stitt2016NPDRfigure.jpg}
        \subcaption{}
        \label{subfigintro:NPDR-1}
    \end{subfigure}
    \begin{subfigure}[b]{0.246\textwidth}
        \centering
        \includegraphics[width = \textwidth]{figures/introduction/DanisDavisPDRFigureCropped.pdf}
        \subcaption{}
        \label{subfigintro:NPDR-2}
    \end{subfigure}
    \caption{Retinal images recorded of two patients presenting with mild, and severe Non-Proliferative retinopathy.~\subref{subfigintro:NPDR-1}) colour fundus image (left) shows the formation of exudates (small white specks), and micro-aneurysms (cloudy areas surrounding the vessels and arteries). The fluorescence image recorded using fluorescein as a contrast agent (right) better shows these areas of micro-aneurysms as clusters of white surrounding the sharp white vasculature as well as an areas displaying restricted blood flow (white arrow). \subref{subfigintro:NPDR-1}) reproduced from Fig.~1 of~\citeauthor{stitt2016progress}~\cite{stitt2016progress}. \subref{subfigintro:NPDR-2}) reproduced from Fig.~1 of~\citeauthor{danis2008proliferative}~\cite{danis2008proliferative}}
    \label{fig:introNPDR}
\end{figure}
 In the more advanced stages of the disease the lack of sufficient blood flow to the choroid causes new irregular vessels to grow – sometimes through the retina itself~\cite{kowluru2007oxidative}. This latter stage of disease is known as Proliferative Diabetic Retinopathy (PDR).  Through routine imaging, signs of proliferation in the retinal vasculature and signs of oedemas are monitored with the progression of the disease being classified into PDR, and Non-Proliferative Diabetic Retinopathy (NPDR).
 \begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{annotatedFigure}
            {\includegraphics[width=\textwidth]{figures/introduction/DanisDavisPDRFigureA.pdf}}
            \annotatedFigureBox{0.6,0.45}{0.72,0.26}{2}{0.72,0.250}
            \annotatedFigureBox{0.115,0.51}{0.370,0.430}{1}{0.38,0.420}
        \end{annotatedFigure}
        \subcaption{}
        \label{subfigintro:PDRA}
    \end{subfigure}
    %
    \hfill
    %
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{annotatedFigure}
            {\includegraphics[width=\textwidth]{figures/introduction/DanisDavisPDRFigureB.pdf}}
        \end{annotatedFigure}
        \subcaption{}
        \label{subfigintro:PDRB}
    \end{subfigure}
    %
    \hfill
    %
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{annotatedFigure}
            {\includegraphics[width=\textwidth]{figures/introduction/DanisDavisPDRFigureC.pdf}}
        \end{annotatedFigure}
        \subcaption{}
        \label{subfigintro:PDRC}
    \end{subfigure}
    \caption{Images recorded of a patient with Proliferative Diabetic Retinopathy. \subref{subfigintro:PDRA}) shows a site of severe pre-retinal haemorrhage (1), and trans-retinal vessels near the optic disc (2).~\subref{subfigintro:PDRB}) show the same retina three weeks after the photo-coagulation surgery - after imaging the haemorrhaged blood was removed from the vitreous humour in a vitrectomy. \subref{subfigintro:PDRC}) shows the patient 8 weeks after the photo-coagulation and vitrectomy where visual acuity has improved from 20/60 pre-intervention to 20/30 in this image. At a 4 year follow-up vision has improved to 20/20. Figure adapted from Fig.~5 of~\citeauthor{danis2008proliferative}~\cite{danis2008proliferative}.}
    \label{figintro:PDR}
\end{figure}
 Treatment of Diabetic retinopathy is normally two-fold: the patient can improve control of blood-glucose concentration and reduce fluctuations and events of hyperglycaemia and hypoglycaemia; and through surgical interventions to reduce the loss of vision due to oedemas. Surgical treatment involves: laser photo coagulation to ablate, and seal, any leaking vessels; and as follow-up any haemorrhaged blood is removed and the missing volume of vitreous humour is made up with saline. These surgeries can slow the effects of PDR but the best intervention is still tight glycaemic control and regular retinal screening with sufficient sensitivity to diabetic retinopathy in its non-proliferative stage~\cite{chan2010resistance}. Tightening glycaemic control – has been shown to reduce the risk of developing diabetic retinopathy by \qty{35}{\percent}~\cite{fong2004retinopathy}.
\FloatBarrier
\subsubsection{Stargardts Disease}\label{subsubsec:intro-stargardt}
Stargardts Disease is a heritable form of macular degeneration caused by a mutation of the ABCA4 gene on chromosome 1. Affecting around 1 in \numrange{8000}{10000}~\cite{tanna2017stargardt,monica1999analysis,tsang2018stargardt}, retinal images show the formation, and build-up of yellowish flecks in the RPE, centred on the fovea, and presenting as hypo-fluorescent regions in autofluorescence images. These characteristic ``flecks’’ are similar in appearance to drusen but over time cause dysfunction in the RPE leading to irrecoverable loss of central vision~\cite{mcbain2012progression}.
\begin{figure}[htp]
    \centering
    \begin{annotatedFigure}{\includegraphics[width=0.95\textwidth]{figures/introduction/StargardtsFigure.pdf}}
        \annotatedFigureText{0.17,0.92}{white}{0.3}{a)}
        \annotatedFigureText{0.51,0.92}{white}{0.3}{b)}

        \annotatedFigureBox{0.18,0.52}{0.28,0.38}{1}{0.285,0.375}
        \annotatedFigureBox{0.70,0.70}{0.765,0.63}{2}{0.77,0.625}
    \end{annotatedFigure}

    \caption{Fluorescence images of the retina showing: a) a patient with advanced Stargardts disease where a large area of the macula has atrophied (1) - showing no fluorescence; and b) A cluster of hypo-fluorescent ``flecks'', denoted by the red highlighted region (2), that are a common marker of Stargardts disease. Adapted from Figures 27.1 and 27.2 of~\citeauthor{tsang2018stargardt}~\cite{tsang2018stargardt}.}
    \label{fig:stargardts}
\end{figure}
Currently there are no documented treatments for slowing the progression of the disease or literature on the process by which the clusters of flecks form and grow~\cite{huang2022stargardt}.  Stargardts Disease is diagnosed by the presence of ``flecks'' in fundus autofluorescence images. The development of an imaging technique that can detect the formation of this earlier in its progression could be vital for researching the pathophysiology of the disease and informing treatments.
\FloatBarrier
\subsection{Current Retinal Imaging Devices \\ and Modalities}
\subsubsection{Fundus Camera}
The most common device for routine assessments of retinal health is the fundus camera. The Fundus camera records images by flood illuminating, and imaging, the retina over a FOV of \qtyrange{50}{80}{\degree}. Annular illumination is used to improve image quality by utilising the Gulstrand principle by separating illumination and imaging light~\cite{gullstrand1910neue}. The key advantage of the fundus camera is the variety of imaging modalities. While brightfield imaging and autofluorescence imaging are popular techniques such as Fluorescein Angiography (FA) and Indo-Cyanine Green imaging are used for monitoring blood flow in the retina. FA and ICG involve intravenously injecting the patient with fluorescent dye which then circulates throughout the retinal vasculature thus revealing areas of the retina with low-circulation and at risk of damage~\cite{stanga2003indocyanine,bennett2001fundamentals,spaide2015retinal}.  Despite being a flexible imaging platform fundus cameras are limited by the FOV they can image – covering only \qty{15}{\percent} of the retina – which can lead to conditions such as peripheral retinal detachments being undiagnosed until loss of central vision occurs.
\subsubsection{Scanning Laser Ophthalmoscopy}
Instead of flood illuminating the retina and recording an image with an array-detector, the Scanning Laser Ophthalmoscope (SLO) raster scans a laser source across the retina and records fluctuations in reflected intensity with a single-pixel detector (PMT) \cite{webb1980flying}. Optos SLO systems use a pair of elliptical mirrors to increase the angle of the laser illumination through the pupil to achieve illumination over a \qty{220}{\degree} FOV or \qty{82}{\percent} of the retina without the need to dilate the pupil~\cite{ashraf2022comparison,keane2014retinal}. By not requiring the pupil to be dilated patient comfort is improved and eliminates the side-affect of the dilation agent where acute close-angle Glaucoma is brought upon~\cite{yang2019drug}.  Confocal imaging using an aperture fitted to the detection path, conjugate to the retina, can be used to increase contrast in retinal images and allow some optical sectioning~\cite{webb1980flying}. SLO systems do come with the drawback of being significantly more expensive than fundus cameras. This limits adoption and motivates the need for a low-cost imaging device with an equivalent ability for earlier diagnosis of retina disease.
\FloatBarrier
\subsubsection{Optical Coherence Tomography}
Optical Coherence Tomography (OCT) leverages the principles of Michelson Interferometry to allow axial imaging of the retina. In OCT, reflected light from the retina is interfered with the illumination beam and the intensity of the resultant intensity pattern is recorded. The path length of the illumination beam can then be tuned thus interfering with deeper layers of the retina – forming a depth profile of a single point with sub-micron layer resolution as shown in~\cref{fig:octfig}. Typically, the beam is scanned across the retina to build up line scanned images through features of interest~\cite{huang1991optical,podoleanu2012optical}. OCT is most effective for studying structural changes in the retina such as Age-Related Macular Degeneration~\cite{yehoshua2011natural}
\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{figures/introduction/OCTFigure.pdf}
    \caption{High resolution OCT line-scan of the retina where changes in intensity as a function of axial depth of \qty{820}{\um} has a \qty{40}{\decibel}. The scale bar shown represents a \qty{250}{\um} depth. Reproduced from Fig.~1 of \citeauthor{drexler2001ultrahigh}\cite{drexler2001ultrahigh}}
    \label{fig:octfig}
\end{figure}
\FloatBarrier
\section{Concepts of Fluorescence and \\ Fluorescence Lifetime Imaging}
In this section basic concepts of fluorescence, and the fluorescence lifetime, will be described and techniques in the field of Fluorescence lifetime imaging will be discussed.
\FloatBarrier
\subsection{Mechanics of Fluorescence Lifetimes}
Fluorescence is a radiative process where photons are emitted from a substance due to the excitation and subsequent relaxation of electronic singlet states. This process is commonly visualised using a Jablonski diagram in~\cref{figintro:jablonski}.
\begin{figure}[htp]
    \centering
    \includegraphics[width = 0.8\textwidth]{figures/introduction/JablonskiDiagram.pdf}
    \caption{Jablonski diagram of the mechanics behind fluorescence. $S_{0}, S_{1}, S_{2}$, denoted by bold lines, represent the ground and the first two excited singlet states. Non-radiative processes such as internal conversion between vibrational states (grey dashed) and inter-system crossing (purple) allow for the emission of a fluorescence photon ($S_{1}\rightarrow S_{0}$, shown in green, or a phosphorescence photon ($ S_{1}\rightarrow T_{1}\rightarrow S_{0} $), shown in red}
    \label{figintro:jablonski}
\end{figure}
Absorption of photons promote an electron from the ground electronic singlet state $S_{0}$, to a vibrational state within a higher electronic state, $S_{1}, S_{2}$,\ldots, $S_{n}$. Non-radiative internal conversion relax the electron in the fluorophore back into the $S_{1}$ state. The electron can then decay back into the $S_{0}$ state by emitting a fluorescence photon or undergo an inter-system crossing to the first triplet-state, $T_{1}$, and then decay to the ground state to produce a phosphorescence photon. 
These radiative and non-radiative processes occur over different time scales: absorption occurs over \qty{e-15}{\second}; internal conversions and inter-system crossings occur \qty{e-12}{\second}; phosphorescence decays take place over time-scales of \qtyrange{e-7}{e-3}{\second}~\cite{lakowicz2013fluorescencespectroscopybook}. Of key interest in this thesis is the decay times due to fluorescence which occur over a few nanoseconds~\cite{lakowicz2013fluorescencespectroscopybook}.
The process of fluorescence is random i.e. within a single unit-area the excited state of every electron is not depopulated at the same time. It is thus more useful to consider the average time the fluorophore remains in the excited state, $S_{1}$ - this is the fluorescence lifetime. The time-dependent intensity of fluorescence can then be modelled from the rate-of-change of concentration of fluorophores in the excited state $S_{1}$ is [$S_{1}$]:
\begin{equation}
    \frac{d}{dt}[S_{1}] = -\Gamma [S_{1}]\,,
    \label{eqintro:conc}
\end{equation}
where $\Gamma$ is the rate at which fluorescence photons are produced and is the inverse of the fluorescence lifetime ($\Gamma = \nicefrac{1}{\tau}$). By then associating the measured time-evolved intensity with the concentration, $[S_{1}]$, the fluorescence decay can be modelled:
\begin{align}
    \frac{d}{dt}I(t) &= -\Gamma I(t)\\
    \implies I(t) &= I_{0}\exp(-\nicefrac{t}{\tau})\,.
    \label{eqintro:lifetime}
\end{align}
For mixtures of fluorophores, and fluorophores with unique molecular properties, multi-exponential decays with $N$ fluorescence lifetimes are described using:
\begin{equation}
    I(t) = I_{0}\sum_{n>0}^{N}\alpha_{n}\exp(-\nicefrac{t}{\tau_{n}})
    \label{eqintro:multiexp}
\end{equation}
\FloatBarrier
\subsection{Stokes Shifts and Spectral Emission Characteristics}
The vibrational states of $S_{1}$ reachable through absorption of an excitation photon and the subsequent relaxation into the different vibrational states of $S_{0}$ incurs a small energy loss and results in a phenomena called the "Stokes Shift" where the emitted fluorescence photon is always of a longer wavelength than the excitation photon. When measuring the comparatively weak fluorescence signal the Stoke's Shift means that any reflected light originating from the excitation source can be filtered out.
\FloatBarrier
\subsection{Detection Schemes for FLIM}
Before a fluorescence lifetime can be recovered first the time resolved decay must be recorded. Typically one of two methods are used for FLIM are: ``Time Domain'' or ``Frequency Domain''. Each method has its benefits and unique methods for recovering the fluorescence lifetime. Before the advent of SPAD arrays the excitation source would be scanned across the sample and fluorescence decays would be recorded using a Photo-Multiplier Tube (PMT) with single-photon counting capabilities. The progression in new generation SPAD arrays, and gated sCMOS detectors, are quickly making widefield FLIM a more feasible and attractive method for FLIM imaging.
\FloatBarrier
\subsubsection{Time-Domain FLIM}
Time-Domain FLIM techniques predominantly use a pulsed laser source, with pulse-width $\approx\qty{100}{\ps}$ and repetition rates of $\approx \qtyrange{50}{100}{\mega\hertz}$, to excite fluorescence and then over a series of pulses, sample the fluorescence as it decays over time. The fluorescence lifetime can be then extracted using one of many techniques. \\
In this section, the two popular techniques of Time-Correlated Single Photon Counting and Time-Gated FLIM are described.
\paragraph*{Time-Correlated Single-Photon Counting FLIM\\}
In Time-Correlated Single-Photon Counting (TCSPC) FLIM, fluorescence is excited with a short, typically $<\qty{100}{\ps}$, laser pulse, and the arrival of the time of the first photon incident on the detector is measured. Since fluorescence is a random process, the entire fluorescence decay can be recorded - with precision of \qtyrange{5}{50}{\ps} - by building a histogram of photon arrival times over the course of multiple laser pulses. In wide-field FLIM, typically these detectors take the form of an array of Single Photon Avalanche Diodes (SPADs) with separate, on-pixel, electronics for correlating the photon arrival times with their respective laser pulses - Time-Correlated Photon-Counting (TCSPC). TCSPC-SPADs have two methods for correlating arriving photons to their laser pulse: forward-counting and backward-counting mode. In forward-counting mode, as shown in \cref{introfig:tcspc}, the laser signals that pulse has been emitted, and the time interval between this signal and the first detected photon is used as the photon arrival time. 
\begin{figure}[htbp]
    \centering
    \includegraphics[width = 0.8\textwidth]{figures/introduction/TCSPCDiagram.pdf}
    \caption{Diagram demonstrating the principle of Time Correlated Single Photon Counting in forward-counting mode. The photon arrival time is recorded by starting a timer when a laser pulse is emitted and is stopped when the first photon is detected. Any subsequent photon incident on the detector during its dwell time are not recorded.}
    \label{introfig:tcspc}
\end{figure}
Conversely, backward-counting schemes are often preferred in scenarios with photon starved regimes, and where the refractory period between recording a photon arrival and resetting the timing electronics is longer than a laser period. Now the time interval between a photon being detected and the next signalled laser pulse is used as the photon arrival time - decreasing the number of refractory periods where photons are not detected and allowing histograms to be built over a shorter integration time. 
\\
Additionally, the nature of TCSPC leads to a behaviour of ``photon pile-up'' where the fluorescence decay histograms are biased towards early arrival times due to laser pulses causing multiple photons to be excited and impinge on the detector within a single laser period. Since only the first photon can be counted the rest are discarded and early arriving photons will be over-represented in the histogram. The intensity of the laser source should then be attenuated to prevent this ``photon pile-up''.
\\
The fluorescence lifetime can then be recovered using: non-linear least-squares fitting techniques, statistical techniques, or Fourier based techniques - all of which have their own unique advantages and disadvantages. These techniques are discussed in more detail in~\cref{sec:intro-lifetimemethods}.
\paragraph*{Time Gated FLIM\\}\label{sec:intro-gatedFLIM}
For Time-Gated FLIM detection schemes, the sample to be imaged is exited using a laser source with a short pulse width and high repetition rate but the fluorescence decay is sampled using 2 or more exposure windows of equal width, $\approx\qtyrange{1}{2}{\ns}$, over multiple laser pulses (see \cref{subfigintro:tgflim}). To achieve this a typically a gated camera is synchronised to the laser source and multiple images are recorded with exposures $\approx\qtyrange{1}{2}{\ns}$ where the delay to the first image and between images, and the number of images, are customised for each imaging scenario. 
\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.47\textwidth}
        \centering
        \includegraphics[width = \textwidth]{figures/introduction/TimeGatedFlim.pdf}
        \caption{}
        \label{subfigintro:tgflim}
    \end{subfigure}
    \begin{subfigure}[b]{0.47\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/introduction/TimeGatedFlimBiExp.pdf}
        \caption{}
        \label{subfigintro:tgflimbi}
    \end{subfigure}
    \caption{Detection schemes used for resolving single exponential (\subref{subfigintro:tgflim})  and bi-exponential (\subref{subfigintro:tgflimbi}) using the Time Gated FLIM method. Each acquisition window, $T_{n}$, has equal integration time, $\Delta t$ and is synchronised to the laser pulse that excites fluorescence.}
    \label{figintro:tgflim}
\end{figure}
For mono-exponential decays, the fluorescence lifetime, $\tau$, is then recovered using the ratio of the number of photons detected in each image and the length of exposure for each image:
\begin{equation}\label{eqintro:rld}
    \tau = \frac{\Delta t}{\ln(T_{1}/T_{2})}\,,
\end{equation}
where $\Delta T$ is the width of the gates, and $T_{1}$ and $T_{2}$ are the number of photons detected in each image. For fluorophores exhibiting a bi-exponential decay both fluorescence lifetimes can still be resolved albeit now 4 gated images are required (\cref{subfigintro:tgflimbi}). For contiguous gates this means each gate is narrower in the time domain - fewer photons are detected - and each image exhibiting higher noise. Using wider, overlapping, gates reduces the noise in each gated image at the cost of longer image acquisition times since multiple gated images cannot be recorded per laser pulse. The model for recovering both lifetime components, $\tau_{1}$ and $\tau_{2}$, and relative concentrations, $a_{1}$ and $a_{2}$, becomes more verbose and for brevity is not described here but can be found in Eq.~16-25 of~\citeauthor{sharman1999error} where it is defined for both contiguous and overlapping gates~\cite{sharman1999error}.
\\
The key attractions of Time-Gated FLIM lie in its capability for fast and efficient recording and determination of fluorescence lifetimes - with video-rate Wide-field FLIM being reported~\cite{elson2004real,ulku2020wide}. This does come at the expense of being limited to resolving fewer than 2 fluorescence lifetimes with reduced accuracy when compared to SPAD-TCSPC detection schemes~\cite{ballew1989error}. For this thesis it was deemed this decreased lifetime resolution rendered it unsuitable for attempting to discriminate, and quantify, retinal fluorophore concentrations.
\FloatBarrier
\subsubsection{Frequency Domain FLIM}\label{sec:intro-fdFLIM}
Fluorescence lifetime imaging can also be achieved in the frequency domain. Here the intensity of the excitation source or the gain of the detector are periodically modulated. 
Shown in \cref{figintro:fdflim}, there is a change in amplitude and the phase shift of the recorded fluorescence signal - when compared with the excitation waveform - and is dependent on the quantum efficiency of the fluorophore as well as its fluorescence lifetime~\cite{lakowicz1991lifetime, verveer2009frequency}. Frequency domain FLIM has been demonstrated in both point-scanning based systems with a single PMT~\cite{serafino2023direct} and in widefield imaging using a gated-intensifier camera which records images across multiple phase intervals~\cite{chen2013practical}. To avoid errors in recovering fluorescence lifetimes for widefield imaging due to aliasing, the phase intervals, corresponding to a sampling frequency, $\omega_{s}$ must be chosen such that the laser modulation,$\omega_{l}$, is sampled by the detector, above the Nyquist limit such that $w_{l} > 2\omega_{s}$.
\begin{figure}[htbp]
    \centering
    \includegraphics[width = 0.5\textwidth]{figures/introduction/FDflim.pdf}
    \caption{Example of principle of Frequency-Domain FLIM. A continuous wave source (black line) is intensity modulated with a frequency, $\omega = \SI{80}{\mega\hertz}$. A fluorophore with lifetime, $\tau = \SI{5}{\nano\second}$, causes a lifetime dependent phase, $\phi$, and amplitude, $M$, modulation in the recorded fluorescence intensity.}
    \label{figintro:fdflim}
\end{figure}
\paragraph*{Recovering Lifetimes in Frequency-Domain FLIM}
The fluorescence lifetime, $\tau$, can then be recovered from the measured phase-shift, $\phi$:
\begin{equation}\label{eqintro:fdlifetime}
    \tau = \frac{1}{\omega}\tan(\phi)\,,
\end{equation}
where $\omega$ is the laser modulation frequency expressed in units of \unit{\radian\per\second}
Or from the relative change in the amplitude from in the recorded fluorescence signal, 
\begin{equation}\label{eqintro:fdmodulation}
    M = \frac{1}{\sqrt{1 + \omega^{2}\tau^{2}}}\,,
\end{equation}
where the modulation, $M$, is equivalent to the ratio, $\nicefrac{m_{F}}{m_L}$, of the amplitude of the recorded fluorescence signal, $m_{F}$, and the amplitude of the laser modulation signal, $m_{L}$.
\\
Lifetime components from mixtures of fluorophores can also be recovered by using multiple modulation frequencies where typically for $n$-lifetimes a signal with $n$-harmonics of a sinusoid with frequency, $w$, are required. In the limit, a signal composed of only the odd-ordered harmonics now approaches a square-wave modulation although now the fluorescence signal must now be Nyquist sampled at $w_{l} > 2n\omega_{s}$.~\citeauthor{squire2000multiple} demonstrated this square-wave modulation in a frequency-domain FLIM experiment where structures inside HeLa cells were stained: with green fluorescence-protein staining the Golgi, an organelle responsible for distributing proteins outwith the cell; and yellow fluorescent-protein staining the cells nucleus. Despite these structures physically overlapping each other - Golgi surround the nuclei - both stains were successfully unmixed with images of fluorophore concentration and lifetime being commensurate with what was present in literature.
\FloatBarrier
\section{Fluorescence Lifetime Recovery Methods}\label{sec:intro-lifetimemethods}
In this project a TCSPC-SPAD array is used, the Horiba FLIMera, and is described in more detail in~\cref{subsec:flimeradetails}. For this detection scheme, there are various methods of recovering fluorescence lifetimes from the histograms of photon arrival times - each with their own unique capabilities and drawbacks. Mainly, these techniques can be broken down into fitting-based techniques, and purported ``fit-free'' techniques. Fitting based techniques tend to be computationally intensive but more accurate whereas ``fit-free'' techniques tend to trade-off accuracy in recovering lifetimes for a lowered computational burden or unique methods of visualising the distribution of fluorescence lifetimes across the sample. This section will cover the four most common FLIM analysis techniques although it should be noted the recovering of the fluorescence lifetime was not extensively used in favour of the bespoke SFLIM unmixing technique developed in~\cref{chap:tensSFLIM}.
\FloatBarrier
\subsection{Least-Squares Fitting Based Techniques}\label{subsec:intro-lsqfitting}
Fitting based techniques will typically use an iterative approach where the difference between a chosen fitting model typically a mono-exponential or bi-exponential decay,
\begin{equation}\label{eq:multiexp}
    I(t) = A\sum_{n=0}^{N}a_{n}\exp\bigg(\frac{-(t-t_{0})}{\tau_{n}}\bigg) + c\,,
\end{equation}
and the measured histogram is then minimised.
Most popular least-squares fitting routines use the Levenberg-Marquadt Algorithm where the parameter space - in this case $\{A,c,\tau_{n}, a_{n}\}\rvert_{n=0}^{N}$, is iteratively traversed in the direction which approaches a global-minima the fastest given a initial estimate of the fitting parameters. The number of exponentials chosen for the fitting model is normally informed by some prior knowledge of the number of fluorophores in the sample and their reported lifetimes but often fewer exponential terms are chosen due to low SNR in histograms.
\FloatBarrier
\subsubsection{The Instrument Response Function}
Within the histograms recorded using TCPSC-FLIM, the fluorescence decay is contaminated by the non-zero width of the pulse from the excitations source, dispersion from optics in the imaging system, and the temporal response of the SPAD-TCSPC array itself. This temporal response is known as the Instrument Response Function (IRF):
\begin{equation}\label{eq:irf}
    I(t) = IRF(t) \circledast  A\sum_{n=0}^{N}a_{n}\exp\bigg(\frac{-(t-t_{0})}{\tau_{n}}\bigg) +c 
\end{equation}
The measured histogram is then represented as a convolution of the IRF with the multi-exponential decay model with the effect of biasing the recovered fluorescence lifetimes~\cite{trinh2021biochemical}.
The IRF can be characterised by measuring backscattered light through the system by placing a silver mirror at the sample plane. Other methods involve imaging a fluorophore with fluorescence lifetimes shorter than a single time-bin - meaning the second term in the convolution approximates a Dirac-Delta function~\cite{margineanu2025calibration}. Rigorous characterisation of the IRF is not required for the tail-fitting method to be discussed next - however some indication of the approximate width of the IRF is beneficial.
\FloatBarrier
\subsubsection{Tail-Fitting}\label{subsubsec:tailfitting}
The tail-fitting approach to recovering fluorescence lifetimes avoids the need to rigorously characterise the IRF of the FLIM imaging system by adjusting the window over which the histogram is fitted. The fitting window is usually chosen such it starts when the IRF decreases to an SNR approaches 1 and the fitting window ends when the SNR of the decay approaches 1. The fitting window, and multi-exponential model is then tuned until the $\chi^{2}$, or goodness-of-fit - is satisfactory. In histograms with low numbers of photons, small adjustments of this fitting window can introduce significant changes in the fitted lifetime - biasing the fit towards lifetimes that are in good agreement with the decay within the fitting window rather than the histogram as a whole. 
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/introduction/tailfittingfigure.pdf}
    \caption{Tail-fitting can be used to recover fluorescence lifetimes from TCSPC histograms without prior knowledge of the IRF. A chosen multi-exponential decay is fitted within a window (region bounded by the vertical orange lines). A TCSPC histogram of a Gaussian IRF with FWHM of \qty{750}{\ps} convolved with a single lifetime component of \qty{2.4}{\ns} with Poissonian noise applied equivalent to detecting 1000 photons. Tail-fitting yielded a recovered lifetime of \qty{2.1}{\ns}}
    \label{fig:introtailfit}
\end{figure}
\FloatBarrier
\subsubsection{Re-convolution Based Fitting}\label{subsubsec:reconv}
If the IRF of the FLIM has been sufficiently characterised, then re-convolution based fitting can be used to more accurately determine fluorescence lifetimes. For this approach the fitting model is modified from the multi-exponential decay in~\cref{eqintro:multiexp} to the model in~\cref{eq:irf} which now includes the convolution of the IRF with the decay function. From the simulations shown in \cref{fig:introreconv} and \cref{fig:introtailfit}, this type of fitting allows less deviation from the ground-truth when recovering fluorescence lifetimes, given sufficient photon counts.
\begin{figure}[htp]
    \centering
    \includegraphics[width = 0.8\textwidth]{figures/introduction/reconvfittingfigure.pdf}
    \caption{Reconvolution fitting incorporates the IRF by convolving the IRF (green line) with the chosen fitting model and minimising the differences between this convolution and the TCSPC histogram (grey line) to produce a line of best fit (red line). With 1000 photons, a lifetime of \qty{2.2}{\ns} is recovered from a simulated decay with lifetime of \qty{2.4}{\ns} and convolved with a Gaussian IRF with FWHM of \qty{750}{\ps}. Reconvolution fitting was performed using the \textit{FLIMlib} python package - the same fitting engine as the popular FLIMJ ImageJ plug-in~\cite{gao2020flimj}}
    \label{fig:introreconv}
\end{figure}
\FloatBarrier
\subsection{Rapid-Lifetime Determination}\label{subsec:intro-rapidlifetime}
The fitting based techniques described in~\cref{subsubsec:tailfitting} and~\cref{subsubsec:reconv}, are often computationally intensive, often requiring $>\qty{5}{\minute}$ to fit a typical FLIM image consisting of $\approx50,000$ pixels, and in the case of reconvolution-based fitting an additional measurement of the IRF is required. To address this, Rapid-Lifetime Determination (RLD) methods were developed predominately for time-gated FLIM detection schemes but are equally applicable to TCPSC based FLIM. Lifetimes are recovered in exactly the same way as described in \cref{sec:intro-gatedFLIM} but now the two time-gated images are formed by summing together multiple time-bins of a fluorescence histogram.
\FloatBarrier
\subsection{Phasor Analysis}\label{subsec:intro-phasor}
Phasor analysis is a computationally cheap, Fourier-based, method for recovering fluorescence lifetimes from histograms recorded with a TSCPC Time-Domain FLIM detection scheme. Computationally, the phasor transform can be implemented using a Fast-Fourier Transform for real-time determination of lifetimes~\cite{levitt2020quantitative,sorrells2021real}. The phasor transform maps each area-normalised histogram, $I(t)$, to a point in phasor-space, $(g,s)$,
\begin{align}{\label{eq:intro-phasortransform}}
    g &= \int_{0}^{T}I(t)\cos(2\pi ft)dt = real(\mathcal{F}\{I(t)\}\rvert_{n=1})\\
    s &= \int_{0}^{T}I(t)\sin(2\pi ft)dt = imag(\mathcal{F}\{I(t)\}\rvert_{n=1})
\end{align}
where $f$ refers to the repetition rate of the pulsed excitation source when $t$ is in units of time. 
For mono-exponential decay lifetime,
\begin{equation}\label{eq:intro-phasorlifetime}
    \tau = \frac{1}{2\pi f}\bigg(\frac{s}{g}\bigg)\,,
\end{equation}
can then be recovered from these phasor coordinates, $s$ and $g$.
\FloatBarrier
\subsubsection{Lifetime Segmentation in Phasor FLIM}
A key convenience of the phasor transform is the ability to easily segment images by exploiting the fact that fluorophores with distinct lifetimes will occupy distinct areas in phasor-space. As shown in~\cref{fig:phasorbiunmix}, fluorophores expressing a single lifetime will occupy a point along the semi-circle with diameter of 1, and centred on $g=0.5, s=0$. Fluorophores exhibiting $N$-lifetimes will occupy points within an $N$-polygon where the vertices, lying on this semi-circle, represent the $N$-lifetime component. The relative concentration of each component can then be found using a process akin to Vertex Components Analysis - an analysis technique used frequently in remote sensing and spectral imaging~\cite{nascimento2005vertex,dean2014fast}.
\begin{figure}
    \centering
    \includegraphics[width = 0.7\textwidth]{figures/sflim/phasor-unmixing/PhasorUnmix.pdf}
    \caption{Depiction of unmixing a combination fluorophores using phasor analysis. For this mixture of 2 fluorophores the pure endmembers are represented as single exponential decays (black circle and green star) and thus have phasors lying on the unit circle. A third phasor consisting of a mixture of two fluorophores, with relative abundances $\alpha_{1}$ and $\alpha_{2}$, lies upon a line intersecting both endmember phasors. The relative abundances are recovered using the fractional lengths $f_{1}$ and $f_{2}$ : $\alpha_{1} = \frac{f_{1}}{f_{1} + f_{2}}$, $\alpha_{2} = \frac{f_{2}}{f_{1} + f_{2}}$ }
    \label{fig:phasorbiunmix}
\end{figure}
\FloatBarrier
\subsubsection{Compensating for the IRF in Phasor FLIM}
The IRF of the FLIM imaging system can be accounted for in phasor analysis quite simply by expressing the phasor-coordinates, $(g,s)$ of a TCSPC histogram, and the IRF, in polar-form $(m = \sqrt{g^{2} + s^{2}}, \varphi = \arctan({\nicefrac{s}{g}}) )$. In phasor-space the IRF has the effect of applying a rotation, around the origin, and stretching of a phasor representing a pure mono-exponential decay $(m_{DECAY}, \varphi_{DECAY})$:
\begin{align}\label{eq:intro-phasorirf}
    m_{DECAY} &= \frac{m_{TCSPC}}{m_{IRF}}\\
    \varphi_{DECAY} &= \varphi_{TCSPC} - \varphi_{IRF}
\end{align}
where now the IRF, ($m_{IRF}, \varphi_{IRF}$), can be compensated for in a measurement \\ $(m_{TCSPC}, \varphi_{TCSPC})$ to yield the phasor representing the fluorescence decay.
\FloatBarrier
\subsubsection{Phasor Analysis Beyond FLIM}\label{subsubsec:into-phasorbeyond}
Phasor analysis has also seen usage beyond standard FLIM imaging. For spectrally-resolved FLIM measurements it has been adapted for unmixing of mixtures of fluorophores - to be explored in \cref{sec:phasor-sflim} - for samples with stained structures. In Fluorescence microscopy, phasor analysis has also seen use as a computational analysis technique for fluorescence spectroscopy~\cite{fereidouni2012spectral} and implemented as an optical analysis technique~\cite{wang2023single,hedde2021phasor}. For the latter case, a beamsplitter and pair of fluorescence emission filters with sinusoidal and co-sinusoidal transmission functions allow images of the $s$, and $g$ phasor-coordinates to be directly recorded. Finally, it should be highlighted that phasor analysis was previously, and still is, a common technique for analysing AC electronic circuits and signals~\cite{semmlow2005circuits}.
\FloatBarrier
\section{FLIO - Fluorescence Lifetime \\ Imaging Ophthalmoscopy}
Fluorescence Lifetime Imaging Ophthalmoscopy (FLIO) has emerged in the past 20 years with the goal of exploiting the heightened ability of FLIM to discriminate fluorophores. the presence or changes in fluorescent biomarkers could be used to signal the presence of retinal disease or be a useful marker of disease progression. The following section describes this FLIO imaging device and summarises current efforts in establishing links between the indicators of retinal disease and the distribution of fluorescence lifetimes in the retina.
\FloatBarrier
\subsection{Description of the Heidelberg - Fluorescence Lifetime Imaging Ophthalmoscope}
In most of the literature in FLIO, a single class of device is used and is based on a modified commercial SLO~\cite{dysli2017fluorescence,dysli2014quantitative,dysli2017AMDfluorescence,sauer2018patterns,dysli2016autofluorescence,schmidt2017fundus, dysli2016Stargardtfluorescence,solberg2019retinal}. The Heidelberg Spectralis is a confocal SLO with additional capabilities of performing OCT imaging and has been modified to allow for fluorescence lifetime imaging over two spectral bands. Fluorescence is excited by a \qty{200}{\pico\watt} laser source (\qty{86}{\ps} at \qty{80}{\mega\hertz} repetition rate) at a wavelength of \qty{460}{\nm} and the fluorescence is split into a short wavelength channel (\qtyrange{500}{560}{\nm}) and a long wavelength channel (\qty{560}{\nm}) using a pair of PMT’s with TCSPC electronics to record photon arrival times. These two spectral channels were influenced by~\citeauthor{schweitzer2007towards} to more effectively discriminate fluorescence from the fluorophores AGE, and FAD, from lipofuscin~\cite{schweitzer2007towards}. Lipofuscin is the dominant source of fluorescence in wavelengths above \qty{560}{\nm} and is thus the dominant fluorescence lifetime present in the long wavelength channel.
With the Heidelberg FLIO system, a~\numproduct{256 x 256} pixel fluorescence-lifetime image is recorded of the retina over an FOV of \qty{30}{\degree} over an acquisition window of \qty{60}{\second}. Due to the long integration time required to collect a sufficient number of photons in FLIO imaging, the comparatively faster, natural movements of the eye (\qtyrange{25}{1000}{\ms} – see~\cref{sec:motionreg}) would degrade the image and introduce motion artefacts and blurring. This motion is then compensated for using blood vessels in IR images of the retina recorded, at video-rate, with an additional IR source and PMT detector.
\FloatBarrier
\subsection{Connections between Retinal Disease and Fluorescence Lifetime}
\FloatBarrier
\subsubsection{Fluorescence Lifetimes in AMD}
AMD presents as an attractive candidate to study using the FLIO technique given that is one of the most prevalent retinal diseases and outcomes from treatment improve greatly when detected early enough~\cite{clemons2005risk}.~\citeauthor{dysli2017AMDfluorescence} used FLIO to assess whether there are any discernible correlations between fluorescence lifetimes and the progression of AMD. Of a cohort of 64 patients, they found that drusen displayed longer fluorescence lifetimes than the surrounding tissues, and that in general the lifetimes of retinas showing signs of AMD are longer than age, and sex, matched healthy retinas \cite{dysli2017AMDfluorescence}. Further, \citeauthor{sauer2018patterns} found that in ``dry’’ AMD patients presented with a ring of shorter lifetimes (see \cref{fig:flioamd}) in the long-spectral channel $>\qty{560}{\nm}$ around the macula although \qty{36}{\percent} or imaged patients without AMD also displayed this characteristic ring~\cite{sauer2018patterns}. In both publications the authors posited that since this change is fluorescence is only seen in the long-spectral channel then it could be due to changes in lipofuscin distribution, or the accumulation of bisretinoids in the RPE~\cite{sauer2018patterns}. A shortcoming of these publications is that individual drusen could not be distinguished using FLIO alone where OCT imaging was required to confirm the presence of drusen.
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/introduction/AMDFLIOFigure.pdf}
    \caption{Fundus autofluorescence, and fluorescence lifetimes images recorded of patients that are healty, with non-exudative AMD, and advanced Geographic Atrophy. Images of retinas with AMD, and GA both show rings of increased fluorescence lifetimes compared to the surrounding tissue - \qty{500}{\ps} in the affected area, and \qty{300}{\ps} in the surrounding retinal tissue. Figure adapted from Figure 1 and 6 of \citeauthor{sauer2018patterns}\cite{sauer2018patterns}}
    \label{fig:flioamd}
\end{figure}
Areas of geographic atrophy in the advanced stage of dry AMD show increased fluorescence lifetimes when compared to surrounding retinal tissue and as shown in~\cref{fig:flioamd}, these areas of longer lifetimes form unique patterns dependent on the nature of the macular atrophy~\cite{dysli2016autofluorescence}.~\citeauthor{dysli2016autofluorescence} reported that in the short spectral channel, lifetimes are \qty{152}{\percent} longer, and in the long spectral channel, the increase is \qty{83}{\percent} over a cohort of 41 patients with varying forms of advanced AMD~\cite{dysli2016autofluorescence}. While this is a promising result for FLIO this stage of disease progression still presents with permanent vision loss.

\FloatBarrier
\subsubsection{Fluorescence Lifetimes in Diabetic Retinopathy}
In diabetic retinopathy the ability to detect abnormalities in the retinal vasculature before visual symptoms occur is critical for preventing permanent vision loss. The progression of diabetic retinopathy has been linked to the accumulation of Advanced Glycation Endproducts (AGE) – a dominant fluorophore found in the retina and lens~\cite{schweitzer2007towards}. Discriminating AGEs from standard fundus autofluorescence images is prohibitively difficult due to high overlap of fluorescence emission spectra of retinal fluorophores. Quantification of AGEs using FLIO would enable diabetic retinopathy to be diagnosed earlier in its progression allowing for more effective treatments. In both~\citeauthor{schweitzer2015fluorescence} and \citeauthor{schmidt2017fundus} showed type 2 diabetics show increased fluorescence lifetimes compared to healthy volunteers even without showing signs of diabetic retinopathy~\cite{schweitzer2015fluorescence}. They suggested that repeated events of hyperglycaemia would lead to AGEs accumulating in the lens and the neuronal layer of the retina. Later,~\citeauthor{schmidt2017fundus} showed that fluorescence lifetimes in the lens - recorded by adjusting the focal plane of the FLIO device onto the eye’s lens~\cite{schmidt2017fundus} - can be used to discriminate non-proliferative diabetic retinopathy from healthy volunteers with high sensitivity of \qty{90.9}{\percent}, and specificity of \qty{71.4}{\percent}.
\FloatBarrier
\subsubsection{Fluorescence Lifetimes in Stargardts Disease}
Despite there being no effective treatments for Stargardts disease, FLIO could be a useful technique for diagnosing and tracking progression from the initial biochemical dysfunction stages of the disease. The characteristic flecks associated with Stargardts Disease appear in fluorescence lifetimes images of the retina as fleck shaped regions with lifetimes shorter and longer than the surrounding retinal tissue. In autofluorescence images these short-lifetime flecks are absent and ~\citeauthor{dysli2016Stargardtfluorescence} theorised that these short lifetime flecks might progress into long-lifetimes flecks~\cite{dysli2016Stargardtfluorescence}. 
\begin{figure}[htp]
    \centering
    \begin{annotatedFigure}{\includegraphics[width=0.95\textwidth]{figures/introduction/FLIOStargardtFigure.pdf}}
        \annotatedFigureBox{0.615,0.785}{0.64,0.74}{1}{0.65,0.74}
        \annotatedFigureBox{0.605,0.290}{0.63,0.255}{2}{0.64,0.245}
    \end{annotatedFigure}

    \caption{After a 44-month follow-up, the characteristic flecks of Stargardt Disease show lengthened fluorescence lifetimes in the centre of the fleck that radiate outward (1) and (2). These flecks also show progression in both fundus autofluorescence and OCT images. Figure reproduced from Fig.~4 of~\citeauthor{solberg2019retinal}\cite{solberg2019retinal}.}
    \label{fig:fliostargardt}
\end{figure}
A longitudinal study on patients with Stargardts Disease revealed that in early stages of the disease short-lifetime flecks appear approximately twice as often as long-lifetimes flecks in the early stages of disease. Follow-up images of fluorescence lifetimes showed that in \qty{75}{\percent} of cases that short-lifetime flecks – that would not normally be visible in autofluorescence images – transitioned to long-lifetime flecks~\cite{solberg2019retinal}.~\cref{fig:fliostargardt} shows the progression of short to long-lifetimes begins with the long-lifetimes forming in the centre of the fleck and then radiating outwards.
From these two publications, FLIO appears to be a good candidate for longitudinal study of Stargardts to further understand its progression, pathophysiology, and to develop effective treatments.

\FloatBarrier
\subsection{Limitations of Qualitative Assessment for Understanding Disease Pathophysiology}
While FLIO is still a young field, there is a lack of quantitative analyses on fluorophore concentrations. In the bulk of the literature, the connection between disease and fluorescence lifetimes are spoken of in terms of relative changes in lifetime when compared with either healthy retinas or the surrounding retinal tissue. In some of the published works there are hypotheses offered for why fluorescence lifetimes change~\cite{solberg2019retinal,dysli2017AMDfluorescence,schmidt2017fundus} but these works also focus on qualitative differences in fluorescence lifetimes in the retina. Quantitative measurements of the concentration, and distribution, of retinal fluorophores would enable deeper understanding of the biochemical changes that occur in the retina during the formation and progression of retinal disease. The use of lifetime fitting, would not be the most effective method of quantifying fluorophore concentrations. Mixtures of common retinal fluorophores would exhibit fluorescence decay models requiring at least $>\numrange{1e6}{1e7}$ photons (see~\cref{sec:lifeunmix}) motivating the need for a new method of unmixing fluorescent endmembers from their fluorescence decay profile.
\FloatBarrier
\section{Methods of Measuring Metabolic Function \\ in the Retina}\label{sec:retinaoximetry}
\FloatBarrier
One of the key aims in this thesis is to utilise time-resolved fluorescence to map metabolic activity across the retina and so the existing techniques of measuring metabolic activity should also be discussed. Retinal oximetry is the most widely used technique for measuring metabolic activity in the retina where the differences in the absorption spectra between oxygenated and deoxygenated haemoglobin can be leveraged to infer the oxygen saturation in the retinal vasculature. Implementations of retinal oximetry utilise a standard fundus camera but with a modified detection path where two detectors record spectral images, in parallel, with bands chosen to coincide with: the isobestic point, $\approx \qty{550}{\nm}$, where the absorption of oxygenation and deoxygenated haemoglobin is equal; and an oxygen sensitive band where the two spectra are maximally different~\cite{smith1999optimum,rilven2017retinal}. Similar implementations involve using three spectral bands but retinal oximetry using 8 spectral bands has also been demonstrated using Image-Replicating Imaging Spectrometer (IRIS) for snapshot oximetry using a single detector yielding high-spectral resolution, and sensitivity to changes in oxygenation~\cite{mackenzie2016vivo, mackenzie2018oximetry,choudhary2013assessment}. While the changes between normal and oxygen deprived conditions (hypoxia) can be easily measured. The systematic errors due to multi-path reflection on vessels~\cite{beach2024potential}, skin and fundus pigmentation~\cite{hirsch2023dual}, and patient-to-patient variability, make it unsuitable for measuring small changes in oxygenation thought to occur with onset and slow progression of retina disease~\cite{told2018method}.