

\setstretch{2}
\section{Motivation and Project Aims}
The human eye is capable of forming images over large depth's of field with single photon sensitivity. The eye is also susceptible to disease that often resulting permanent loss of vision if left undiagnosed and untreated. One of the most common retinal diseases, affecting the elderly, Age-Related Macular Degeneration AMD, affects \qty{20}{\percent} of the population and in a \num{12} month period this disease can progress the initial symptoms to permanent loss of some central vision~\cite{lim2012age}. Routine and regular retinal imaging is a key tool in the early detection of retinal disease, and for developing understanding of disease pathophysiology and effective treatment. Current retinal imaging techniques, such as scanning laser ophthalmoscopy (SLO), aim to detect structure abnormalities in images of the retina surface covering \qty{82}{\percent} (\qty{200}{\degree} FOV) of the retinal surface (OPTOS Monaco, Silverstone SLO) and resolution of \qty{15}{\um}~\cite{ashraf2022comparison} to diagnose and track progression of common retinal disease such as AMD, Glaucoma, Diabetic Retinopathy, and retinal detachments.
\\
Here lies a fundamental issue with current interventions in retinal disease - they occur after physical damage to the retina is detected or changes in vision are reported by the patient. At this stage, treatment options degrade into maintaining and abating permanent loss of vision. If instead, the progression of disease can be tracked at the level of local biochemical imbalances or metabolic dysfunction - before the occurrence of physical damage to vision - disease can be more effectively detected, studied, and treated.
Naturally Fluorescent biomarkers, can be quantitatively imaged to all metabolic function in the retina to be measured. For example: a biomarker found in the retina, Flavin Adenine Dinucleotide (FAD), is a by-product of the consumption of oxygen and could indicate local metabolic health in the retina; and Advanced Glycation End-products (AGEs) are linked with the progression of diabetic retinopathy \addcite. Fluorescence imaging in the retina - termed fundus autofluorescence imaging in the literature - is widely used, qualitatively, in clinical ophthalmology for resolving markers of AMD progression, drusen, and damage to other retinal structures~\cite{yung2016clinical}. Fluorescence imaging of the retina is hindered by several fundamental limitations. Namely, the low intensity threshold for safe exposure coupled with the feint signal produced from excited fluorophores of interest being polluted by fluorescent clutter results in high noise images with poor contrast and resolution (when compared to wide-field reflectance images). This dominant fluorescent clutter also degrades the ability to quantify the concentration of individual fluorophores and map their distribution across the retina even with advanced spectral imaging techniques.
\\
Fluorescence Lifetime Imaging Microscopy (FLIM) is an emergent field of microscopy where the differences in nanosecond-scale time that a fluorophore remains excited for is used a contrast mediums to form images. FLIM brings unique advantages in that the fluorescence lifetime is intrinsic to each fluorophore but is also invariant  to the local concentration or quantum efficiency of the fluorophore. This means that weakly emitting fluorophores of interest can be isolated from complex mixtures  if the limitations of low-photon counts or high shot-noise can be overcome. Commonly, biological structures, or proteins of interest are labelled with dyes to fluoresce much more intensely than the autofluorescence of endogenous fluorophores allowing more complex mechanisms to be exploited: viscosity and tension within tissue can be probed~\cite{ringer2017multiplexing, kashirina2020monitoring}; intramolecular distances can be measured through F\"orster Resonance Energy Transfer~\cite{haenni2013intramolecular}; and even sub-diffraction limit volumetric imaging can be achieved ~\cite{shtengel2009interferometric}. In the retina, endogenous fluorophores of interest exhibit high-overlap of their fluorescence emission spectra and fluorescence decay properties introducing additional challenges.
\\
The techniques of FLIM have recently been adapted for clinical ophthalmology in the field of Fluorescence lifetime Imaging Ophthalmoscopy (FLIO) to explore the diagnostic use that fluorescence lifetimes may offer~\cite{dysli2017fluorescence}. Fluorescence lifetimes are extracted from histograms of arrival times of fluorescence photons to construct a map of fluorescence lifetimes across the retina. With this device the connection between measured fluorescence lifetimes and retinal disease progression was explored by qualitatively comparing lifetime maps of age and gender matched healthy patients with patients exhibiting a retinal disease such as AMD, Diabetic Retinopathy, and Stargardts disease~\cite{zinkernagel2019fluorescence}. These \textit{in-vivo} studies focus on qualitative comparisons in part due to the relative youth of the field as well as the poor understanding of the specific biochemical imbalances that occur in the retina, and the body, at the onset of retinal disease.
\\
Fluorescence Lifetime Imaging (FLI) is a relatively new field of microscopy where the picosecond - nanosecond fluorescence lifetime - the average time a fluorophore remains excited - is used as a contrast medium to form images similar to how the number of detected photons is used in conventional fluorescence intensity imaging. FLI brings unique advantages in that the fluorescence lifetime is intrinsic to each fluorophore but is also invariant to the local fluorophore concentration and quantum efficiency of the fluorophore but can also reveal information about the local pH, temperature, and the local embedding matrix in cellular organisms. This in principle means that weakly fluorescent fluorophores of interest can be isolated from complex mixtures but the noise induced by low photon counts inherent to autofluorescence imaging affect the accuracy and precision of this unmixing process.
To overcome the low signal produced by endogenous fluorophore, in practice, FLI is commonly performed on samples labelled with dyes with the fluorescence lifetime, excitation and emission spectra, and the binding site specifically engineered for each application. This enables more complex dynamics and processes to be investigated such as staining specific cellular structures~\cite{maibohm2019syncrgb}, measuring viscosity and tension in tissues~\cite{ringer2017multiplexing, kashirina2020monitoring}, probing intramolecular distances and interactions using F\"orster Resonance Energy Transfer~\cite{haenni2013intramolecular}, and volumetric super-resolution imaging~\cite{shtengel2009interferometric}.
\\
A key deficiency in current retinal imaging modalities is the ability to quantitatively assess retinal health. Previously, measurements of vascular oxygen concentrations in retinal vasculature have been reported~\cite{stefansson2019retinal,mordant2011spectral} - using the spectral properties of oxygenated and un-oxygenated haemoglobin - however the uncertainties in the measurements of $O_{2}$ concentrations are larger than the variability that would typically be experienced throughout the progression of a retinal disease, or chronic disease such as Multiple Sclerosis. There is potential for the added dimension of the fluorescence lifetime to facilitate a similar quantitative approach to monitoring retinal metabolic health but the efficient use of the available signal will be paramount for ensuring this technology can be feasibly implemented into current diagnostic practises.
\\
In this thesis, a Commercial-Of-The-Shelf (COTS) fundus camera is modified to enable spectrally resoled FLIM measurements of the retina,  and a new method of recovering fluorophore concentrations from SFLIM measurements is developed. Using this new instrument and algorithm, the feasibility of measuring retinal FAD concentrations in the retina is assessed by inducing changes in oxygen consumption anathematised rat and measuring commensurate changes in retinal FAD concentrations.
\FloatBarrier
\section{Morphology The Eye and \\Common Retinal Diseases}
\FloatBarrier
\subsection{Morphology of the Eye}
\FloatBarrier
\subsection{Common Retinal diseases - Their Indicators \\and Progression}
\FloatBarrier
\subsection{Current Retinal Imaging Devices \\ and Modalities}
\FloatBarrier
\section{Concepts of Fluorescence and \\ Fluorescence Lifetime Imaging}
\FloatBarrier
\subsection{Mechanics of Fluorescence Lifetimes}
Fluorescence is radiative process where photons are emitted from a substance due to the excitation and subsequent relaxation of electronic singlet states in a substance. This process is commonly visualised using a Jablonski diagram (~\cref{figintro:jablonski}):
\begin{figure}[htbp]
    \centering
    \includegraphics[width = 0.8\textwidth]{figures/introduction/JablonskiDiagram.pdf}
    \caption{Jablonski diagram of the mechanics behind fluorescence. $S_{0}, S_{1}, S_{2}$, denoted by bold lines, represent the ground and the first two excited singlet states. Non-radiative processes such as internal conversion between vibrational states (grey dashed) and inter-system crossing (purple) allow for the emission of a fluorescence photon ($S_{1}\rightarrow S_{0}$, shown in green, or a phosphorescence photon ($ S_{1}\rightarrow T_{1}\rightarrow S_{0} $), shown in red}
    \label{figintro:jablonski}
\end{figure}

Absorption of impinged photons promote an electron from the ground electronic singlet state $S_{0}$, to a vibrational state within a higher electronic state, $S_{1},S_{2}$ etc. Non-radiative internal conversion relax the electron in the fluorphore back into the $S_{1}$ state. The electron can then decay back into the $S_{0}$ state by emitting a fluorescence photon or undergo an inter-system crossing to the first triplet-state, $T_{1}$, and then decay to the ground state to produce a phosphorescence photon. 
These radiative and no-radiative processes occur over different time scales: absorption occurs over \qty{e-15}{\second}; internal conversions and inter-system crossings occur \qty{e-12}{\second}; phospoherscence decays take place over time-scales of \qtyrange{e-7}{e-3}{\second}~\cite{lakowicz2013fluorescencespectroscopybook}. Of key interest in this thesis is the decay times due to fluorescne which occur over a few nanoseconds~\cite{lakowicz2013fluorescencespectroscopybook}.
The process of fluorescence is random i.e within a single unit-area the excited state of every electron is not depopulated at the same time. It is thus more useful to consider the average time the fluorophore remains in the excited state, $S_{1}$ - this is the fluorescence lifetime. The time-dependent intensity of fluorescence can then be modelled from the rate-of-change of concentration of fluorophores in the excited state [$S_{1}$]:
\begin{equation}
    \frac{d}{dt}[S_{1}] = -\Gamma [S_{1}]
    \label{eqintro:conc}
\end{equation}
Where $\Gamma$ is the rate at which fluorescence photons are produced and is the inverse of the fluorescence lifetime ($\Gamma = \nicefrac{1}{\tau}$). By then associating the measured time evolved intensity of with the concentration $[S_{1}]$ the fluorescence decay can be modelled:
\begin{align}
    \frac{d}{dt}I(t) &= -\Gamma I(t)\\
    \implies I(t) &= I_{0}\exp(-\nicefrac{t}{\tau})
    \label{eqintro:lifetime}
\end{align}
For mixtures of fluorophores, and fluorophores with specific molecular properties, multi-exponential decays with $N$ fluorescence lifetimes are described using:
\begin{equation}
    I(t) = I_{0}\sum_{n>0}^{N}\alpha_{n}\exp(-\nicefrac{t}{\tau_{n}})
    \label{eqintro:multiexp}
\end{equation}
\subsection{Stokes Shifts and Spectral Emission Characteristics}
The vibrational states of $S_{1}$ reachable through absorption of a excitation photon and the subsequent relaxation into the different vibrational states of $S_{0}$ incurs a small energy loss and results in a phenomena called the "Stokes Shift" where the emitted fluorescence photon is always of a lower energy and longer wavelength than the excitation photon. When measuring the comparatively weak fluorescence signal the Stoke's Shift means that any reflected light originating from the excitation source can be filtered out.
\FloatBarrier
\subsection{Detection Schemes for FLIM}
Before a fluorescence lifetime can be recovered first the time resolved decay must be recorded. Typically one of two methods are used for this: ``Time Domain'' or ``Frequency Domain'' FLIM. Each method has its benefits and unique methods for recovering the fluorescence lifetime where typically lifetime accuracy is exchanged for high pixel detectors in widefield FLIM. Early FLIM systems would scan the excitation source across the sample and record the fluorescence decay using a Photo-Multiplier Tube (PMT) with single-photon counting capabilities.
\FloatBarrier
\subsubsection{Time Domain FLIM}
Time Domain FLIM techniques predominantly use a pulsed laser source, with pulse-width $\approx\qty{100}{\ps}$ and repetition rates of $\approx \qtyrange{50}{100}{\mega\hertz}$, to excite fluorescence and then record multiple samples of fluorescence as it decays over time from which the fluorescence lifetime can be extracted using multiple techniques. In this section, the two popular techniques of Time-Correlated Single Photon Counting and Time-Gated FLIM are described.
\paragraph*{Time-Correlated Single-Photon Counting FLIM}
In Time-Correlated Single-Photon Counting (TCSPC) FLIM, fluorescence is excited with a short, typically $<\qty{100}{\ps}$, laser pulse, and the arrival of the time of the first photon incident on the detector is measured. Since fluorescence is a random process, the entire fluorescence decay can be resolved with \qtyrange{5}{50}{\ps} precision by building a histogram of photon arrival times over the course of multiple laser pulses. In widefield FLIM, typically these detectors take the form of an array of Single Photon Avalanche Diodes (SPADs) with separate, on-pixel, electronics for correlating the photon arrival times with their respective laser pulses - Time-Correlated Photon-Counting (TCSPC). TCSPC-SPADs have two methods for correlating arriving photons to their laser pulse: forward and backward counting mode. In forward counting mode the laser signals that pulse has been emitted and the time interval between this pulse and the first detected photon is used as the photon arrival time. Conversely, backward counting schemes are often preferred in scenarios with photon starved regimes and where the refractory period between recording a photon arrival and resetting the timing electronics is longer than a laser period. Now the time interval between a photon being detected and the next signalled laser pulse is used as the photon arrival time - decreasing the number of refractory periods where photons are not detected and allowing histograms to be built with lower integration time. 
Additionally, the nature of TCSPC leads to a behaviour known in the literature as ``photon pile-up'' where the fluorescence decay histograms are biased towards early arrival times due to high intensity laser pulses causing multiple photons to impinge on the detector within a single laser period. Since only the first photon can be counted the rest are discarded and early arriving photons will be over-represented  in the histogram. The intensity of the laser source should then be tuned to prevent this ``photon pile-up''.
\\
As will be discussed in,\cref{sec:intro-lifetimemethods}, the fluorescence lifetime is normally recovered from the photon arrival histograms using a non-linear least-squares fitting routine.
\textcolor{red}{Add better figure on TCSPC}
\begin{figure}[htbp]
    \centering
    \includegraphics[width = 0.8\textwidth]{figures/introduction/TCSPCDiagram.pdf}
    \caption{Diagram demonstrating the principle of Time Correlated Single Photon Counting in forward mode. The photon arrival time is recorded by starting a timer when a laser pulse is emitted and is stopped when the first photon is detected. Any subsequent photon incident on the detector during its dwell time are not recorded.}
    \label{introfig:tcspc}
\end{figure}
\paragraph*{Time Gated FLIM}\label{sec:intro-gatedFLIM}
For Time-Gated FLIM detection schemes the sample to be imaged is also exited using a laser source with a short pulse width and high repetition rate but the fluorescence decay is recorded over 2 or more exposure windows of equal width, $\approx\qtyrange{1}{2}{\ns}$, for multiple laser pulses (see \cref{subfigintro:tgflim}). To achieve this a typically a gated camera is synchronised to the laser source and multiple images are recorded with exposures $\approx\qtyrange{1}{2}{\ns}$ where the delay to the first image and between images, and the number of images, are customised for each imaging scenario. 
\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.47\textwidth}
        \centering
        \includegraphics[width = \textwidth]{figures/introduction/TimeGatedFlim.pdf}
        \caption{}
        \label{subfigintro:tgflim}
    \end{subfigure}
    \begin{subfigure}[b]{0.47\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/introduction/TimeGatedFlimBiExp.pdf}
        \caption{}
        \label{subfigintro:tgflimbi}
    \end{subfigure}
    \caption{Detection schemes used for resolving single exponential (\subref{subfigintro:tgflim})  and biexponential (\subref{subfigintro:tgflimbi}) using the Time Gated FLIM method. Each acquisition window, $T_{n}$, has equal integration time, $\Delta t$ and is synchronised to the laser pulse that excites fluorescence.}
    \label{figintro:tgflim}
\end{figure}
For mono-exponential decays, the fluorescence lifetime, $\tau$, is then recovered using \cref{eqintro:rld} based upon the ratio of the number of photons detected in each image and the length of exposure for each image
\begin{equation}\label{eqintro:rld}
    \tau = \frac{\Delta t}{\ln(T_{1}/T_{2})} \quad 
\end{equation}
Where $\Delta T$ is the width of the gates, and $T_{1}$ and $T_{2}$ are the number of photons detected in each image. For fluorophores exhibiting a bi-exponential decay the both fluorescence lifetimes can still be resolved albeit now 4 gated images are required (\cref{subfigintro:tgflimbi}). For contiguous gates this means each gate is narrower in time leading to each image exhibiting higher noise. This can be compensated for by overlapping the gates. The model for recovering both lifetime components, $\tau_{1}$ and $\tau_{2}$, and relative concentrations, $a_{1}$ and $a_{2}$, is much more verbose and for brevity is not listed here but can be found in Eq.~16-25 of~\citeauthor{sharman1999error} where it is defined for both contiguous and overlapping gates~\cite{sharman1999error}.
\\
The key attractions of Time-Gated FLIM lie in its capability for fast and efficient recording and determination of fluorescence lifetimes - with video-rate Widefield FLIM being reported~\cite{elson2004real,ulku2020wide}. This does come at the expense of being limited to resolving fewer than 2 fluorescence lifetimes with reduced accuracy when compared to SPAD-TCSPC detection schemes\cite{ballew1989error}. For this thesis it was deemed this decreased lifetime resolution rendered it unsuitable for attempting to discriminate, and quantify, retinal fluorophores.
\FloatBarrier
\subsubsection{Frequency Domain FLIM}\label{sec:intro-fdFLIM}
Fluorescence lifetime imaging can also be achieved in the frequency domain by either periodically modulating the intensity of a continuous-wave excitation source or the gain of a detector. As demonstrated in \cref{figintro:fdflim}, the time-varying intensity of the fluorescence signal (grey line) exhibits a change in phase, and amplitude, when compared to the reference modulation (black line)~\cite{lakowicz1991lifetime, verveer2009frequency}. Frequency domain FLIM has been demonstrated in both point-scanning based systems with a single PMT~\cite{serafino2023direct} and in widefield imaging using a gated intensifier camera which records images across multiple phase intervals~\cite{chen2013practical}. To avoid errors in recovering fluorescence lifetimes for widefield imaging due to aliasing, the phase intervals, corresponding to a sampling frequency, $\omega_{s}$ must be chosen such that the laser modulation,$\omega_{l}$ is sampled, by the detector, above the Nyquist limit such that $w_{l} > 2\omega_{s}$.
\begin{figure}[htbp]
    \centering
    \includegraphics[width = 0.6\textwidth]{figures/introduction/FDflim.pdf}
    \caption{Example of principle of Frequency-Domain FLIM. A continuous wave source (black line) is intensity modulated with a frequency, $\omega = \SI{80}{\mega\hertz}$. A fluorophore with lifetime, $\tau = \SI{5}{\nano\second}$, causes a lifetime dependent phase, $\phi$, and amplitude, $M$, modulation in the recorded fluorescence intensity.}
    \label{figintro:fdflim}
\end{figure}
\paragraph*{Recovering Lifetimes in Frequency-Domain FLIM}
The fluorescence lifetime, $\tau$, can then be recovered from the measured phase-shift, $\phi$, using~\cref{eqintro:fdlifetime}, given the laser modulation frequency $\omega$ converted to units of \unit{\radian\per\second}
\begin{equation}\label{eqintro:fdlifetime}
    \tau = \frac{1}{\omega}\tan(\phi)
\end{equation}
Or from the relative change in the amplitude from in the recorded fluorescence signal, $M$, using~\cref{eqintro:fdmodulation}.
\begin{equation}\label{eqintro:fdmodulation}
    M = \frac{1}{\sqrt{1 + \omega^{2}\tau^{2}}}
\end{equation}
Where the modulation $M$ is equivalent to ratio of the amplitude of the recorded fluorescence signal, $m_{F}$, and the amplitude of the laser modulation signal, $m_{L}$.
\\
Lifetime components from mixtures of fluorophores can also be recovered by using multiple modulation frequencies where typically for $n$-lifetimes a signal with $n$-harmonics of a sinusoid with frequency, $w$, are required. For odd-ordered harmonics, in the limit, this composite signal now approaches a simple square-wave modulation albeit now the fluorescence signal must now be Nyquist sampled at $w_{l} > 2n\omega_{s}$.~\citeauthor{squire2000multiple} demonstrated this square-wave modulation in a frequency-domain FLIM experiment where structures inside HeLa cells were stained: with green fluorescence-protein staining the Golgi, an organelle responsible for distributing proteins outwith the cell; and yellow fluorescent-protein staining the cells nucleus. Despite the these structures physically overlapping each other - Golgi surround the nuclei - both stains were successfully unmixed with images of fluorophore concentration and lifetime being commensurate with what was present in literature.
\FloatBarrier

\section{Fluorescence Lifetime Recovery Methods}\label{sec:intro-lifetimemethods}

\FloatBarrier
\subsection{Least-Squares Fitting Based Techniques}
\FloatBarrier
\subsubsection{The Instrument Response Function}
\FloatBarrier
\subsubsection{Tail-Fitting}
\FloatBarrier
\subsubsection{Re-convolution Based Fitting}
\FloatBarrier
\subsection{Rapid-Lifetime Determination}

\FloatBarrier
\subsection{Phasor Analysis}
Phasor analysis is a computationally cheap, Fourier-based, method for recovering fluorescence lifetimes from histograms recorded with a TSCPC Time-Domain FLIM detection scheme. Computationally, the phasor transform can be implemented Fast-Fourier Transform to enable real-time determination of lifetimes~\cite{levitt2020quantitative,sorrells2021real}. The phasor transform, shown in~\cref{eq:intro-phasortransform} maps each area-normalised histogram, $I(t)$, to a point in phasor-space, $(g,s)$, where $f$ refers to the repetition rate of the pulsed excitation source when $t$ is in units of time. 

\begin{align}{\label{eq:intro-phasortransform}}
    g &= \int_{0}^{T}I(t)\cos(2\pi ft)dt = real(\mathcal{F\{I(t)\}}\rvert_{n=1})\\
    s &= \int_{0}^{T}I(t)\sin(2\pi ft)dt = imag(\mathcal{F\{I(t)\}}\rvert_{n=1})
\end{align}
For mono-exponential decay lifetime,$\tau$, can then be recovered from these phasor coordinates using~\cref{eq:intro-phasorlifetime}
\begin{equation}\label{eq:intro-phasorlifetime}
    \tau = \frac{1}{2\pi f}\bigg(\frac{s}{g}\bigg)
\end{equation}
\subsubsection{Lifetime Segmentation in Phasor FLIM}
A key convenience of the phasor transform is the ability to easily segment images by exploiting the fact that fluorophores with distinct lifetimes will occupy distinct areas in phasor-space. As shown in~\cref{fig:phasorbiunmix}, fluorophores expressing a single lifetime will occupy a point along the semi-circle with diameter of 1, and centred on $g=0.5, s=0$. Fluorophores exhibiting $N$-lifetimes will occupy points within an $N$-polygon where the vertices, lying on this semi-circle, represent the $N$-lifetime component. The relative concentration of each component can then be found using a process akin to Vertex Components Analysis a method used frequently in remote sensing and spectral imaging~\cite{nascimento2005vertex,dean2014fast}.
\begin{figure}
    \centering
    \includegraphics[width = 0.7\textwidth]{figures/sflim/phasor-unmixing/PhasorUnmix.pdf}
    \caption{Depiction of unmixing a combination fluorophores using phasor analysis. For this mixture of 2 fluorophores the pure endmembers are represented as single exponential decays (black circle and green star) and thus have phasors lying on the unit circle. A third phasor consisting of a mixture of two fluorophores, with relative abundances $\alpha_{1}$ and $\alpha_{2}$, lies upon a line intersecting both endmember phasors. The relative abundances are recovered using the fractional lengths $f_{1}$ and $f_{2}$ : $\alpha_{1} = \frac{f_{1}}{f_{1} + f_{2}}$, $\alpha_{2} = \frac{f_{2}}{f_{1} + f_{2}}$ }
    \label{fig:phasorbiunmix}
\end{figure}
\subsubsection{Compensating for the IRF in Phasor FLIM}
The IRF of the FLIM imaging system can be accounted for in phasor analysis quite simply by expressing the phasor-coordinates, $(g,s)$ of a TCSPC histogram, and the IRF, in polar-form $(m = \sqrt{g^{2} + s^{2}}, \varphi = \arctan({\nicefrac{s}{g}}) )$. In phasor-space the IRF has the effect of applying a rotation, around the origin, and stretching of a phasor representing a pure mono-exponential decay $(m_{DECAY}, \varphi_{DECAY})$. \cref{eq:intro-phasorirf}, demonstrates how the IRF, ($m_{IRF}, \varphi_{IRF}$), can be compensated for in a measurement $(m_{TCSPC}, \varphi_{TCSPC})$ to yield the phasor representing the fluorescence decay.
\begin{align}\label{eq:intro-phasorirf}
    m_{DECAY} &= \frac{m_{TCSPC}}{m_{IRF}}\\
    \varphi_{DECAY} &= \varphi_{TCSPC} - \varphi_{IRF}
\end{align}
\FloatBarrier
\subsection{Spectral-FLIM}
\FloatBarrier
\section{Fluorescence Lifetime Imaging Ophthalmoscopy}
\FloatBarrier
\section{FAD As An Indicator of Metabolic Health}
\FloatBarrier
\section{Methods of Measuring Metabolic Function // in the Retina}
\FloatBarrier


\section{Outline}
\begin{itemize}
    \item Motivation / Philosophy - X
        \begin{itemize}
            \item Eye is susceptible to disease. Early detection improves patient outcomes and reduces permanent damage to sight. 
            \item Routine imaging is an important tool for early detection of disease
            \item Current imaging techniques detect physical damage to the retina
            \item Being able to detect metabolic dysfunction in the retina could allow for diseases to be detected before physical damage occurs
        \end{itemize}
    \item The Eye and Retinal Disease
    \begin{itemize}
        \item Anatomy of the Eye
        \begin{itemize}
            \item Overview of constituent parts lens, humours, retina, choroid etc. and a description of what they do
            \item Description of the layers behind the RPE and retina - briefly describe biological function
        \end{itemize}
        \item Common Retinal Diseases - their indicators and progressions
            \begin{itemize}
                \item AMD
                \item Diabetic Retinopathy
                \item Glaucoma
                \item Stargardt's Disease
            \end{itemize}
        \item Current Retinal Imaging Techniques
        \begin{itemize}
            \item Fundus Camera
            \item Scanning Laser Ophthalmoscope
            \item Optical Coherence Tomography
            \item Other Modalities
        \end{itemize}
    \end{itemize}
    \item Fluorescence and Fluorescence Lifetime Imaging
    \begin{itemize}
        \item Requirement / motivation for doing FLIMX
        \item Description of what fluorescence lifetimes are - X
        \item Detection Schemes for FLIM - X
        \item Lifetime recovery and discrimination methods
        \item Spectral FLIM
    \end{itemize}
    \item Fluorescence Lifetime Imaging Ophthalmoscopy
    \begin{itemize}
        \item Overview of Dysli device
        \item Diseases studied and interpretation of results - how do they fit in with understanding disease ,early detection
    \end{itemize}
    \item FAD as in indicator for metabolic health and metabolic activity of the retina
    \begin{itemize}
        \item summarise what FAD is
        \item some biology papers tracking FAD - UCL halos one
        \item some FLIM and FAD papers
        \item some papers on measureing metabolic activity in the retina
    \end{itemize}
\end{itemize}


% shite that needs to be reqritten
\section{Background}
\subsection{Morphology of the Eye}
The human eye is a complex organ, typically \SI{24}{\milli\metre} in diameter, capable of an angular resolving power of around \ang{;1;} and detecting single photons~\cite{tinsley2016direct} with a topology similar to a front side illuminated sensor. The eye is composed of many different components:
\subsubsection{Anterior Segment}
The cornea protrudes at the front of the eye - making it non-spherical - and is responsible for providing protection for the lens, as well as contributing more than half of the refractive power of the eye. The pigmented iris and pupil form the aperture of the eye and continuously is adjustable from diameters of \SI{2}{\milli\metre} to \SI{8}{\milli\metre} to account for variable ambient light levels. The eyes crystalline lens has a diameter of \SI{8}{\milli\metre} to \SI{10}{\milli\metre} is then responsible for fine focusing, and forming aberration free images onto the retina covering up to around a \SI{200}{\degree} FOV (with both eyes working as a pair).
The eye also contains two humours: the aqueous humour that resides between the cornea and the lens, and the vitreuos humour which fills the volume behind the lens to retina. These humours continuously flow in and out of the eye and ensure tissues in the eye are fed with nutrients and most importantly maintain the eyes shape.

\subsubsection{Posterior Segment}
The retina is a \SI{250}{\micro\metre} thick photo sensitive multi-layer slice of tissue located at the rear of the eyeball that also houses the vasculature that supplies oxygenated blood to the eye. The top layers of the retina contain the arteries and veins that supply oxygenated blood to the tissue, fed by the ophthalmic artery, and the photoreceptors as well as the inner, and outer, nuclear layers which are responsible for detecting incident photons and and converting them into neuronal activity which is transmitted down the optic nerve through a small gap, devoid of photoreceptors called the optic disk. Around the optic disk the density of photoreceptors varies to make up the different types vision. The macula and fovea contain the highest concentrations of photoreceptors to make up the central vision - $\approx \SI{60}{\degree}$ FOV - with the rest of the retinal surface making up peripheral vision\cite{bringmann2021fovea}. 
Behind the photoreceptors exists the Retinal Pigment Epithelium (RPE) - referred to as the pigment epithelium in Fig.~\ref{figintro:eyeanatomy} - which serves as a support structure for the front most layers of the retina as well as choroid and Bruch's membrane whose main purpose is to provide blood and nutrients to the RPE and photoreceptors.


\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/introduction/AnatomyofEye.png}
        \caption{}
        \label{figintro:eyeball}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/introduction/fasebj2017retinalayer2.pdf}
        \caption{}
        \label{figintro:retinalayer}
    \end{subfigure}
    \caption{Diagram of the key parts that comprise the human eye.~\subref{figintro:eyeball}) breaks down the main structures. Figure from~\citeauthor{kolb2007EyeAnatomy}\cite{kolb2007EyeAnatomy}.~\subref{figintro:retinalayer}) the different layers of the retina. The superficial intermediate, and deep vasculature resides between the Nerve Fibre Layer (NFL), Inner Nuclear Layer (INL), and Outer Nuclear Layer (ONL), respectively. The layers responsible for the conversion of light into neuronal activity are the Inner, and Outer Segments (IS,OS) of the photoreceptors and the Ganglion Cell Layer (GCL) and are supported by the Retinal Pigment Epithelium (RPE). Figure from~\citeauthor{liu2017animal}\cite{liu2017animal}}
    \label{figintro:eyeanatomy}
\end{figure}



% \begin{itemize}
%     \item Morphology
%     \begin{itemize}
%         \item Mention the capabilities of the eye  - resolving single photons, diameter of eye ball, pupil, lens etc. FOV, foveated detection
%         \item Discuss the different layers and their role
%         \begin{itemize}
%             \item Cornea protective cover for the lens
%             \item Lens - 8-10mm in diameter - continuously adjusts to vary focal length, and control aberations. 
%             \item pupil + iris - adjustable aperture to allow resolving of images over longer distances, and variable light levels
%             \item retina - photosensitive part which translates images into signal that are readable by the brain. fovea covers approx. 15degrees with higher spatial resolution than the rest of the retina. The retina also has constituent parts
%             \begin{itemize}
%                 \item photoreceptors composed of rods and cones which are responsible for converting photons into neuronal activity. Rods are the more sensitive that cones with rods being able to the respond to a stimuli of 1-10 photons and ficilitating vision in low light conditions. Cones are responsible for sight in the day time.
%                 \item The eye has a variable density of photoreceptors. The macula forms the central area of vision with the fovea being the most sensitive. 
%                 \item The signals detected by the rods and cones are transmitted down the optic nerve which runs through a small gap, devoid of photo recpeotors, called the optic disk or optic nerve head.
%                 \item RPE - Retinal Pigment Epithelium supports the photo receptors
%                 \item Oxygenated blood is carried to the different parts of the eye via a multi layer network of arteries and veins, fed by the main ophthalmic artery that runs along the optic nerve, located above the photoreceptive layers. 
%                 \item Choroid feeds the RPE, and photo receptors, and retina with blood and nutrients.
%                 \item Use \citep{bringmann2021fovea}\cite{bringmann2021fovea}
%             \end{itemize}
%         \end{itemize}
%     \end{itemize}
% \end{itemize}
\FloatBarrier
\subsection{Pathophysiology of Common Retinal Diseases}
There exists multitudes of different diseases that can affect the retina. For the purpose of this review a short list of disease have been examined to target prevalent diseases and those which are the most attractive / probable applications for fluorescence lifetime imaging. Specifically, the pathology of AMD, both Proliferative and Non-Proliferative Diabetic Retinopathy, and Stargardts Disease will be explored.
% Understanding of the pathophysiology, or how and why a disease progresses can be used to enhance treaments through more effective therapeutics and a detection methods.
% Often in the retina the pathophysiology of disease is not completely understood meaning that patients report of loss / change in vision motivate further examination where diagnosis of retinal disease is made based upon the presence of tell-tale markers of specific diseases.

\subsubsection{Age-related Macular Degeneration}\label{intro:AMD}
\FloatBarrier
\subsubsection{Diabetic Retinopathy}
\FloatBarrier
% \begin{itemize}
%     \item Diabetes is a chronic condition that presents with two main types of pathophysiology but both exhibit the same symptoms - the body can no longer self-regulate the concentration of glucose in the blood due to a deficiency / complete lack of insulin production.
%     \item Even with sufficent medication, wild and prolonged fluctuations in blood - glucose concentrations results often lead to complications such as neuropathy, and retinopathy - the focus of this section.
%     \item DR is driven by two main risk factors - hyperglycemia, and hypertension.
%     \begin{itemize}
%         \item High blood glucose, hyperglycemia, causes higher oxidative stress and formation of AGE's
%         \item 
%         \item Hypertension places increases stress on the microvasucalture (i.e the retinal vasculature)     
%     \end{itemize}
%     \item Macular oedema - blood from the choroid leaks into the vitreous humour. Treatment for this involves removing the oedema with a syringe and replacing lost fluid with saline to maintain intraocular pressure. The site of the oedema is then cauterised with a laser resulting in a dark spot of vision in this area. 
% \end{itemize}

Diabetes is a condition that presents in two main categories, Type 1 and Type 2, but exhibit the same overall symptoms - the inability to regulate the uptake of glucose in the body due to a deficiency in insulin production resulting in having an elevated concentration of glucose in the blood. In Type 1, this deficiency in insulin production stems from a autoimmune response destroying the insulin producing cells in the pancreas. For Type 2 increased insulin resistance or decreased efficiency of insulin uptake results in chronic hyperglycemia without treatment. In both types of diabetes a common complication arising of chronic hyperglycemia is the development of diabetic retinopathy which can result in permanent loss of vision through retinal detachments and macular oedemas~\cite{wang2018diabetic}.
Chronic hyperglycemia - prolonged periods of elevated glucose concentrations in the blood - leads to the formation and Advanced Glycation Endproducts (AGEs) and increased oxidative stress causing cumulative damage to the retinal vasculature and the structures that support retinal capillaries. Damage to vasuclature structures causes a deficiency in oxygenated blood within the retina which the body responds with by growing abnormal blood vessels often through the retina surface. Other common signifiers of retinopathy include the formation of exudates in retina, areas of ischemia, micro-anuerysms and haemorrhages into the vitreous humour, and retinal detachments
Since diabetic retinopathy is a progressive disease it is classified into two broad categories - Non-Proliferative Diabetic Retinopathy (NPDR), and Proliferative Diabetic Retinopathy. In NPDR patients often do not present with changes in their vision but retinal imaging, as depicted in Fig.~\ref{figintro:NPDR}, reveals these micro-anuerysms, exudates, and abnormal vessels. In cases of severe NPDR areas of haemorrhaging are clearly evident and, exudates are resolvable, as well as early signs of abnormal intraretinal vascualture growing to compensate for the inadequate supply of oxygenated blood (Fig. \ref{subfigintro:NPDR-2}) which is used to denote the progression of NPDR into PDR.
\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.65\textwidth}
        \centering
        \includegraphics[width = \textwidth]{figures/introduction/stitt2016NPDRfigure.jpg}
        \subcaption{}
        \label{subfigintro:NPDR-1}
    \end{subfigure}
    \begin{subfigure}[b]{0.246\textwidth}
        \centering
        \includegraphics[width = \textwidth]{figures/introduction/DanisDavisPDRFigureCropped.pdf}
        \subcaption{}
        \label{subfigintro:NPDR-2}
    \end{subfigure}
    \caption{Retinal images recorded of two patients presenting with mild, and severe Non-Proliferative retinopathy.~\subref{subfigintro:NPDR-1}) colour fundus image (left) shows the formation of exudates (small white specks), and micro-aneurysms (cloudy areas surrounding the vessels and arteries). The fluorescence image recorded using fluorescein as a contrast agent (right) better shows these areas of micro-aneurysms as clusters of white surrounding the sharp white vasculature as well as an areas displaying restricted blood flow (white arrow). Subfigure~(\subref{subfigintro:NPDR-1}) and~(\subref{subfigintro:NPDR-2}) from~\citeauthor{stitt2016progress}~\cite{stitt2016progress} and~\citeauthor{danis2008proliferative}~\cite{danis2008proliferative}, respectively.}
    \label{figintro:NPDR}
\end{figure}
When diabetic retinopathy enters the proliferative stage the high risk of vision loss is not only from these malformed intraretinal networks of blood vessels puncturing the retina and haemorrhaging (macular oedemas) but also from the motion of this vessel network causing tractional retinal detachments or 'macular dragging'. Treatment for macular oedemas is typically a virectomy where the haemorrhaged fluid is removed with a syringe and replaced with saline solution to maintain intraocular pressure the sites of these oedemas are then photocoagulated with a laser~\cite{newman2010surgical}.

% \begin{figure}[htbp]
%     \centering
%     \begin{subfigure}[b]{0.325\textwidth}
%         \centering
%         \includegraphics[width = \textwidth]{figures/introduction/DanisDavisPDRFigureA.pdf}
%         \subcaption{}
%         \label{subfigintro:PRDa}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.325\textwidth}
%         \centering
%         \includegraphics[width = \textwidth]{figures/introduction/DanisDavisPDRFigureB.pdf}
%         \subcaption{}
%         \label{subfigintro:PRDb}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[b]{0.325\textwidth}
%         \centering
%         \includegraphics[width = \textwidth]{figures/introduction/DanisDavisPDRFigureC.pdf}
%         \subcaption{}
%         \label{subfigintro:PRDc}
%     \end{subfigure}
%     \caption{Caption. Figure adapted from~\citeauthor{danis2008proliferative}\cite{danis2008proliferative}}
%     \label{figintro:PDR}
% \end{figure}


\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{annotatedFigure}
            {\includegraphics[width=\textwidth]{figures/introduction/DanisDavisPDRFigureA.pdf}}
            \annotatedFigureBox{0.6,0.45}{0.72,0.26}{2}{0.72,0.250}
            \annotatedFigureBox{0.115,0.51}{0.370,0.430}{1}{0.38,0.420}
        \end{annotatedFigure}
        \subcaption{}
        \label{subfigintro:PDRA}
    \end{subfigure}
    %
    \hfill
    %
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{annotatedFigure}
            {\includegraphics[width=\textwidth]{figures/introduction/DanisDavisPDRFigureB.pdf}}
        \end{annotatedFigure}
        \subcaption{}
        \label{subfigintro:PDRB}
    \end{subfigure}
    %
    \hfill
    %
    \begin{subfigure}[b]{0.3\textwidth}
        \centering
        \begin{annotatedFigure}
            {\includegraphics[width=\textwidth]{figures/introduction/DanisDavisPDRFigureC.pdf}}
        \end{annotatedFigure}
        \subcaption{}
        \label{subfigintro:PDRC}
    \end{subfigure}
    \caption{Images recorded of a patient with Proliferative Diabetic Retinopathy. (\subref{subfigintro:PDRA}) shows severe a site of preretinal haemorrhage (1), and transretinal vessels near the optic disc (2).   }
    \label{figintro:PDR}
\end{figure}



% \begin{annotatedFigure}
%     {\includegraphics[width=1.0\linewidth]{black-demo.png}}
%     \annotatedFigureBox{0.084,0.614}{0.394,0.804}{A}{0.084,0.614}%bl
%     \annotatedFigureBox{0.222,0.284}{0.3743,0.4934}{B}{0.3743,0.4934}%tr
%     \annotatedFigureBox{0.555,0.784}{0.6815,0.874}{C}{0.555,0.784}%bl
%     \annotatedFigureBox{0.557,0.322}{0.8985,0.5269}{D}{0.8985,0.5269}%tr
% \end{annotatedFigure}




\subsubsection{Stargardts Disease}
\FloatBarrier
% \subsection{FAD as a Marker For Retinal Disease}

% The mechanism for this begins with the fundamental process where ATP (Adenosine TriPhosphate) is produced by the consumption of oxygen through aerobic respiration \cref{eq:resp} and when this ATP is consumed by metabolic process - FAD amongst other fluorescence flavoproteins are also produced. For the eye, this means that the disruption of metabolic processes and the consumption oxygen, at the genesis of retinal disease, would result in abnormal distributions of FAD across the retina. In the case of diabetic retinopathy this could be used to diagnose proliferation earlier than conventional imaging techniques \addcite where areas of the retina with decreased FAD concentration - brought about by the choroid not supplying the retina with oxygenated blood - could be signify future proliferation. 


% The mechanism for this lies with the process of aerobic respiration \cref{eq:resp} in that when ATP (Adenosine TriPhosphate) is consumed - FAD as well as other flavo-proteins are produced as a byproduct\cite{berg2007biochemistry} and under oxygen starved - hypoxic - conditions (\SI{<15}{\percent} \ce{FiO2}) the concentration of FAD would be lower than when respirating room-air - normoxic conditions (\SI{21}{\percent}\ce{FiO2}). 
% \begin{equation}\label{eq:resp}
%     \ce{C6H12O6 + 6O2 -> 6CO2 + 6H2O + ATP}
% \end{equation}
% After death the concentration of FAD would eventually go to zero when all metabolic processes have ceased and as reported by \citeauthor{martinez2017understanding} in the case of a rats cerebral cortex the FAD leaks into the surrounding tissue forming what was dubbed 'halos', further it was thought that in the case of upon returning to normoxic conditions after a period of hypoxia the metabolic system overproduces FAD - increasing the concentration of FAD above that of standard normoxic conditions. 
\FloatBarrier
\subsection{Retinal Imaging Modalities}

% \FloatBarrier
% \subsection{Fluorescence Theory}
% \FloatBarrier
% Fluorescence is radiative process where photons are emitted from a substance due to the excitation and subsequent relaxation of electronic singlet states in a substance. This process is commonly visualised using a Jablonski diagram (Fig.~\ref{figintro:jablonski}):

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width = 0.8\textwidth]{figures/introduction/JablonskiDiagram.pdf}
%     \caption{Jablonski diagram of the mechanics behind fluorescence. $S_{0}, S_{1}, S_{2}$, denoted by bold lines, represent the ground and the first two excited singlet states. Non-radiative processes such as internal conversion between vibrational states (grey dashed) and inter-system crossing (purple) allow for the emission of a fluorescence photon ($S_{1}\rightarrow S_{0}$, shown in green, or a phosphorescence photon ($ S_{1}\rightarrow T_{1}\rightarrow S_{0} $), shown in red}
%     \label{figintro:jablonski}
% \end{figure}
% More specifically, absorption of impinged photons promotes a electron from the ground electronic singlet state, $S_{0}$, to a vibrational state within a higher electronic state, $S_{1},S_{2}$ etc. Non-radiative internal conversions relax the fluorophore back into the $S_{1}$ state. The fluorophore can then decay back into the $S_{0}$ state emitting a fluorescence photon or undergo the process of inter-system crossing to the first triplet state, $T_{1}$ and then subsequently decay back to the ground state producing a phosphorescence photon.
% These radiative and non-radiative processes occur over different time scales: absorption occurs over \SI{e-15}{s}; internal conversion and intersystem crossing occur over \SI{e-12}{\second}; phosphorescence occurs over times scales from \qtyrange{e-7}{e-3}{\second}; and of key interest in this thesis, fluorescence occurs over a time range of a few nanoseconds~\cite{lakowicz2013fluorescencespectroscopybook}. 
% Since fluorescence is random process - the excited state isn't depopulated at the exact same time - it is more useful to consider the average time that
% the fluorophore remains in the excited state or the fluorescence lifetime. This fluorescence lifetime is intrinsic to the fluorophore and is described in terms of the concentration of fluorophores in the excited state, $S_{1}$:
% \begin{equation}
%     \frac{d}{dt}[S_{1}] = -\Gamma [S_{1}]
%     \label{eqintro:conc}
% \end{equation}
% Where $\Gamma$ is the rate at which fluorescence photons are produced and is the inverse of the fluorescence lifetime ($\Gamma = \nicefrac{1}{\tau}$). By then associating the measured time evolved intensity of with the concentration $[S_{1}]$ the fluorescence decay can be modelled:
% \begin{align}
%     \frac{d}{dt}I(t) &= -\Gamma I(t)\\
%     \implies I(t) &= I_{0}\exp(-\nicefrac{t}{\tau})
%     \label{eqintro:lifetime}
% \end{align}
% For mixtures of fluorophores, and fluorophores with specific molecular properties, multi-exponential decays with mutliple fluorescence lifetimes are exhibited:
% \begin{equation}
%     I(t) = I_{0}\sum_{n>0}^{N}\alpha_{n}\exp(-\nicefrac{t}{\tau_{n}})
%     \label{eqintro:multiexp}
% \end{equation}

% \subsubsection{Stoke's Shift / Spectral Characteristics}
% The vibrational states of $S_{1}$ reachable through absorption of a excitation photon and the subsequent relaxation into the different vibrational states of $S_{0}$ incurs a small energy loss and results in a phenomena called the "Stokes Shift" where the emitted fluorescence photon is always of a lower energy and longer wavelength than the excitation photon. When measuring the comparatively weak fluorescence signal the Stoke's Shift means that any reflected light originating from the excitation source can be filtered out.
% \textcolor{blue}{Add in paragraph about emission spectra being largely independent of excitation, graph of}

%     \item show some excitation and emission spectra for retinal fluorophores
% \subsection{Principles of Fluorescence Lifetime Imaging}
% To extract the fluorescence lifetime from a sample the \qtyrange{10}{20}{\nano\second} long decay must first be resolved. Numerous methods exists using differing excitation sources and detection schemes to accomplish this but they be generally categorised into "Time Domain", and "Frequency Domain".
% \subsubsection{Time Domain FLIM}
% Time domain FLIM techniques typically involve exciting fluorescence with a picosecond pulsed laser source and then recording flux of fluorescence photons as the fluorophore decays in time. In this section two methods will be discussed: Time Correlated Single Photon Counting where fluorescence lifetimes are extracted from histograms of photon arrival times detected with single photon sensitive detectors; and a Gated detection scheme where fluorescence photons are counted during two acquisition windows and the fluorescence lifetimes are recovered using a statistical approach.
% \paragraph*{Time Correlated Single Photon Counting\\}
% In the Time Correlated Single Photon Counting scheme the full fluorescence decay is resolved typically with a resolution of \qtyrange{5}{50}{\pico\second} utilising single photon sensitive detectors, and pulsed laser sources to time tag detected fluorescence photons to the laser pulse that produce them. to excite fluorescence in a sample. In Figure \ref{introfig:tcspc} the forward counting mode is illustrated and the scheme operates as follows: a timer is started when a pulse is emitted from the laser; when the first photon is detected the timer stops and the photon event is time tagged; this process is repeated to build up a histogram of photon arrival times resolving the fluorescence decay. In photon starved conditions, where each laser pulse doesn't always yield a fluorescence photon, a backward counting method can be used which now starts the timer when a photon is detected and the next laser pulse stop the timer. After the histogram has been constructed the fluorescence lifetime can be extracted using one of the methods that will be described in Chapter \ref{chap:flimanalysis} such as reconvolution based fitting, phasor analysis or rapid lifetime analysis.
% The technology used in TCPSC FLIM implementations typically consist of a single pixel SPAD paired with a Time-to-Digital-Converter (TDC) to correlate the photon events generated by a \si{\mega\hertz} pulsed laser source with sub \SI{100}{\pico\second} pulse width that scanned across the sample. While TCSPC in principle limits the photon counting rate to one photon per pulse, SPADs also exhibit a dwell time in excess of a single laser period causing even more photons to be discarded (PicoQuant TimeHarp260) reducing photon counting efficiency and lengthening image acquisition times.

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width = 0.8\textwidth]{figures/introduction/TCSPCDiagram.pdf}
%     \caption{Diagram demonstrating the principle of Time Correlated Single Photon Counting in forward mode. The photon arrival time is recorded by starting a timer when a laser pulse is emitted and is stopped when the first photon is detected. Any subsequent photon incident on the detector during its dwell time are not recorded.}
%     \label{introfig:tcspc}
% \end{figure}

% The nature of single pixel detectors restricts fluorescence lifetime imaging platforms to either costly scanning systems~\cite{sanders1995quantitative}, or lengthy singe-pixel compressive sensing techniques for effective~\cite{yao2019net}. New generation SPAD arrays have become available which feature on-chip, and per-pixel, TDCs allowing for 
% recording fluorescence lifetime images in a snap shot. The limit of these new detectors is still their low resolution and low fill factor - for the example the Horiba Flimera, used in this project, has a resolution of \numproduct{128 x 192}\si{\pixel} with time bin width of
% \qtyrange{33}{47}{\pico\second} and fill factor of \SI{13}{\percent}~\cite{henderson2019192}. The low fill factor of these SPADs is due to each pixel of the SPAD contains the active detector area as well as the TDC on the same layer silicon. Raising the fill factor, and thus increasing photon detection efficiency is achievable through multiple methods such as implementing micro lens arrays; optimisation of TDC, and SPAD electronic; and multi-layer fabrication where the top layer of silicon is devoted to to being the active area of the detector and lower layers host the TDC and other necessary components.


% \paragraph*{Time Gated FLIM\\}\label{sec:gatedflim}
% In Time-Gated FLIM, fluorescence is excited in the same way as TCSPC FLIM but now the fluorescence decay is recorded with a gated camera capturing successive exposures with width $\Delta t \approx\qtyrange{1}{2}{\ns}$.
% Unlike TCPSC-FLIM which resolves the entire decay, Gated FLIM samples the fluorescence decay over multiple contiguous windows and uses the statistics of the measured photon counts to the recover the fluorescence lifetime. As in TCSPC, the fluorophore sample is excited using a pulsed laser source but now a synchronised gated camera (emCCD, gated image intensifier), with single photon sensitivity, records the number of photons within a two or more gates of width, $\Delta t$. The number of gates used determines the number of lifetimes that can resolved, for fluorophores exhibiting a mono-exponential decay 2 gates are required (Fig. \ref{subfigintro:tgflim}), and for bi-exponential decays (Fig. \ref{subfigintro:tgflimbi}) but reports of gating schemes for resolving more complex decay models could not be found in this review of literature. This is likely due to the requirement of more fixed-width gates recording fewer photons with a lower SNR - relative to detection schemes with fewer gates - unsustainably increasing the error in recovered lifetimes for higher order exponential decays. Time Gated FLIM, fundamentally, already trades off precision in recovered fluorescence lifetimes, compared to TCSPC FLIM, for high image throughput and widefield imaging meaning it likely not a suitable technique for studying complex mixtures of fluorophores and accurately unmixing their relative concentrations and lifetimes~\cite{ballew1989error, sharman1999error}.

% \begin{figure}[htbp]
%     \centering
%     \begin{subfigure}[b]{0.47\textwidth}
%         \centering
%         \includegraphics[width = \textwidth]{figures/introduction/TimeGatedFlim.pdf}
%         \caption{}
%         \label{subfigintro:tgflim}
%     \end{subfigure}
%     \begin{subfigure}[b]{0.47\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{figures/introduction/TimeGatedFlimBiExp.pdf}
%         \caption{}
%         \label{subfigintro:tgflimbi}
%     \end{subfigure}
%     \caption{Detection schemes used for resolving single exponential (\subref{subfigintro:tgflim})  and biexponential (\subref{subfigintro:tgflimbi}) using the Time Gated FLIM method. Each acquisition window, $T_{n}$, has equal integration time, $\Delta t$ and is synchronised to the laser pulse that excites fluorescence.}
%     \label{figintro:tgflim}
% \end{figure}
% \begin{equation}
%     \tau = \frac{\Delta t}{\ln(T_{1}/T_{2})} \quad 
%     \label{eqintro:rld}
% \end{equation}



% \subsubsection{Frequency Domain FLIM}
% \FloatBarrier
% Frequency Domain FLIM extracts fluorescence lifetime from the apparent phase shift and amplitude modulation exhibited by a fluorophore that is excited by an intensity modulated light source~\cite{verveer2009frequency}. In this detection scheme, typically, an Acousto-Optic Modulator is used to modulate the intensity of a continuous wave laser or LED source with a fundamental frequency, $\omega$, to excite fluorescence in a single pixel for a scanned system or flood illuminated sample for widefield imaging. A gated image intensifier then records images over different phase intervals such that the modulation frequency is Nyquist sampled (i.e $\omega_{s} > 2 \omega$).

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width = 0.6\textwidth]{figures/introduction/FDflim.pdf}
%     \caption{Example of principle of Frequency Domain FLIM. A continuous wave source (black line) is intensity modulated with a frequency, $\omega = \SI{80}{\mega\hertz}$. A fluorophore with lifetime, $\tau = \SI{5}{\nano\second}$, causes a lifetime dependent phase, $\phi$, and amplitude, $M$, modulation in the recorded fluorescence intensity.}
%     \label{figintro:fdflim}
% \end{figure}
% The fluorescence lifetime is determined from the phase modulation (Eq. \ref{eqintro:fdlifetime}) or the amplitude modulation (Eq. \ref{eqintro:fdmodulation}. These parameters can be recovered by fitting the sampled modulation to a sinusoidal function or estimating the phase modulation with a Fourier transform. In the case of a well calibrated FD-FLIM system and a fluorophore expressing a single exponential decay the estimated phase angle, $\phi$, and the amplitude modulation, $M$, should be equal but in the case of multi-exponential decays multiple modulation frequencies are used to enable discrimination[citation needed], or methods such as Phasor analysis [citation needed] can be used (discussed further in Chapter \ref{chap:flimanalysis}).
% \begin{equation}
%     \tau = \frac{1}{\omega}\tan(\phi)
%     \label{eqintro:fdlifetime}
% \end{equation}
% \begin{equation}
%     M = \frac{1}{\sqrt{1 + \omega^{2}\tau^{2}}}
%     \label{eqintro:fdmodulation}
% \end{equation}

% \subsubsection{Applications of FLIM}
% \FloatBarrier
% In fluorescence intensity imaging the low signal and low contrast inherent to autofluorescence imaging hinders attempts to study cellular microsctructures and cellular dynamics of biological samples. Instead these microstructures are often labelled with multiple dyes designed to bind to specific sites with exhibit desirable fluorescence characteristics such as common peak excitation wavelengths, orthogonal emission spectra, and high quantum yield. Multiple dyes, and thus multiple types of cellular microstructures, can then be discriminated using spectral imaging techniques.


% % fluorescence lifetime is invariant to fluorophore concentration
% % bulk of FLIM imaging involves labelled samples
% % low return signal, compared to reflectance imaging, means that cellular strucutures can be difficult to resolve / discriminate solely using fluorsescence intensity imaging. 
% % Spectral imaging can help resolve this but this requires carefully choosing dyes that can bind to the required sites, share a similar peak excitation wavelength whilst also having a well seperable fluorescence emission spectra. Spectral imaging also comes with several other challenges
% % Recording images over mutliple spectral bands reduces SNR for both widefield and scanned systems or requires longer integration times
% % For widefield imaging spectral images are recorded sequentially at bands - this limiting the cellular dynamics that can be resolved
% % Scanning laser based systems can either record images sequentially or use line detectors arrays / multiple PMT's and diffraction grating / prism for broader spectral resolution (but higher noise), or the fewer detectors over wider bands chosen for each application/dye
% % Since the fluorescence lifetiem is invariant to local fluorophore concentration then FLIM can be used to resolve these cellular dynamics and probe other molecular interactions using dyes now seperated in lifetime rather than spectra. This eliminates the burden of choosing dyes with seperable spectra, similar excitations spectra etc. 
% % This means multiple dyes in a scene can be resolved in a snapshot / single image acquisition and enables the probing of faster cellular dynamic
% % The fluorescence lifetime is also dependent on local molecular interaction such as the metabolic biomarkers NADH, and FAD. In their redox pairs NAD / NADH and FAD / FADH they expresss different lifetimes for their oxidised and reduced states (put numbers in table w/ citation) and has been applied to imaging scenario X, Y, Z for autofluorescence imaging. By examing the ratio of lifetimes for these redox pairs the local metabolic health uptake of oxygent in a biological sample can be inferred which has applications in probing cellular dysfunction and idagnostic medicine
% % fluorescence lifetime is also dependent on pH
% % In fluorescence lifetime imaging these dyes can also be engineered such that the FL varies with a specific parameter that is being probed. Molecular tension / torsion, viscosity, 
% % FRET is also an aspect of FLIM that has seen applications in cellular imaging. In FRET two fluorescence probes are used, a donor, and an acceptor,  (both with different fluorescence lifetimes) in a process known as the Foerster Resonance Energy Transfer where a donor fluorophore is excited, and donates its energy to a nearby acceptor causing it to fluorescence. The ratio donor fluorescence to acceptor fluorescence or the FRET efficiency can be used to probe molecular distances and other cellular dynamics such as X,Y,Z
% %


% \section{Phasor Analysis}\label{sec:phasoranalysis}

% Phasor analysis presents as a fit-free analysis tool for easy segmentation of flourophores but is a technique predominantly used for FLIM imaging of stained samples. To unmix combinations of fluorphores, the linear addition of phasors can be exploited such that the relative abundance of $N$ fluorophores can be unmixed using a technique akin to vertex component analysis where the phasors of the pure endmembers form the vertices of an $N$-polygon and the phasor of a fluorophore to be unmixed lies within that $N$-polygon as is illustrated in (\cref{fig:phasorbiunmix} for the case of unmixing 2 fluorophores. The robustness of this method suffers from the same issues that plague lifetime based unmixing - sensitivity to noise and similarity in endmember lifetime model.


% \begin{figure}
%     \centering
%     \includegraphics[width = 0.7\textwidth]{figures/sflim/phasor-unmixing/PhasorUnmix.pdf}
%     \caption{Depiction of unmixing a combination fluorophores using phasor analysis. For this mixture of 2 fluorophores the pure endmembers are represented as single exponential decays (black circle and green star) and thus have phasors lying on the unit circle. A third phasor consisting of a mixture of two fluorophores, with relative abundances $\alpha_{1}$ and $\alpha_{2}$, lies upon a line intersecting both endmember phasors. The relative abundances are recovered using the fractional lengths $f_{1}$ and $f_{2}$ : $\alpha_{1} = \frac{f_{1}}{f_{1} + f_{2}}$, $\alpha_{2} = \frac{f_{2}}{f_{1} + f_{2}}$ }
%     \label{fig:phasorbiunmix}
% \end{figure}


\subsection{Fluorescence Lifetime Imaging Ophthalmoscopy}
\FloatBarrier
\section{Objectives of Research}\label{sec:objresearch}
\FloatBarrier
